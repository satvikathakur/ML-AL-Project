{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "import os\n",
    "from nltk import tokenize\n",
    "import gensim\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from tensorflow.keras import *\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pickle files...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"loading pickle files...\")\n",
    "data1 = pickle.load(open(\"Embedding_saliency1.pickle\", \"rb\"))\n",
    "data2 = pickle.load(open(\"Embedding_saliency2.pickle\", \"rb\"))\n",
    "data3 = pickle.load(open(\"Embedding_saliency3.pickle\", \"rb\"))\n",
    "data4 = pickle.load(open(\"Embedding_saliency4.pickle\", \"rb\"))\n",
    "data5 = pickle.load(open(\"Embedding_saliency5.pickle\", \"rb\"))\n",
    "data6 = pickle.load(open(\"Embedding_saliency6.pickle\", \"rb\"))\n",
    "data7 = pickle.load(open(\"Embedding_saliency7.pickle\", \"rb\"))\n",
    "data8 = pickle.load(open(\"Embedding_saliency8.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenating data...\n"
     ]
    }
   ],
   "source": [
    "print(\"concatenating data...\")\n",
    "data = np.concatenate((data1, data2, data3, data4, data5, data6, data7, data8), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting x and y...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 250, 300, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"extracting x and y...\")\n",
    "x = data[::2]\n",
    "y = data[1::2]\n",
    "\n",
    "x1 = np.dstack(x)\n",
    "x2 = np.rollaxis(x1, -1)\n",
    "x3 = np.array(x2)\n",
    "x4 =np.expand_dims(x3, 3)\n",
    "x4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: (3, 250, 300, 1) (3,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model print(\"training data:\", x_train.shape, y_train.shape)parameters\n",
    "conv_window_size = (3, 300)\n",
    "num_filters = 50\n",
    "reg = 0.01\n",
    "dropout = 0.5\n",
    "\n",
    "# Training parameters\n",
    "epochs = 10\n",
    "batch_size = 256\n",
    "test_train_ratio = 0.2\n",
    "val_train_ratio = 0.2\n",
    "\n",
    "x_train, y_train = x4,y\n",
    "print(\"training data:\", x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(len(y_train),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: (3, 250, 300, 1) (3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"training data:\", x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convolution network implimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 248, 1, 50)        45050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 1, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 603       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 45,657\n",
      "Trainable params: 45,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv2D(input_shape=(x_train.shape[1], x_train.shape[2],1),\n",
    "                    filters=num_filters,\n",
    "                    kernel_size=conv_window_size,\n",
    "                    padding=\"valid\",\n",
    "                    activation=\"relu\",\n",
    "                    data_format='channels_last'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(num_filters, 1)))    \n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(dropout))\n",
    "model.add(layers.Dense(3, activation='tanh', kernel_regularizer=regularizers.l2(reg)))\n",
    "model.add(layers.Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(reg)))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adadelta(),metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.plot_model( model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = y_train.reshape(len(y_train),1)\n",
    "y_train = y_train.astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (3, 250, 300, 1), numpy.ndarray, (3, 1))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train),x_train.shape,type(y_train),y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.7553 - mae: 1.5000 - val_loss: 0.7553 - val_mae: 1.5000\n",
      "Epoch 2/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7553 - mae: 1.5000 - val_loss: 0.7553 - val_mae: 1.5000\n",
      "Epoch 3/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7553 - mae: 1.5000 - val_loss: 0.7553 - val_mae: 1.5000\n",
      "Epoch 4/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7553 - mae: 1.5000 - val_loss: 0.7553 - val_mae: 1.5000\n",
      "Epoch 5/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7553 - mae: 1.5000 - val_loss: 0.7552 - val_mae: 1.5000\n",
      "Epoch 6/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7552 - mae: 1.5000 - val_loss: 0.7552 - val_mae: 1.5000\n",
      "Epoch 7/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7552 - mae: 1.5000 - val_loss: 0.7552 - val_mae: 1.5000\n",
      "Epoch 8/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7552 - mae: 1.5000 - val_loss: 0.7552 - val_mae: 1.5000\n",
      "Epoch 9/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7552 - mae: 1.5000 - val_loss: 0.7552 - val_mae: 1.5000\n",
      "Epoch 10/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7552 - mae: 1.5000 - val_loss: 0.7552 - val_mae: 1.5000\n",
      "Epoch 11/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7552 - mae: 1.5000 - val_loss: 0.7552 - val_mae: 1.5000\n",
      "Epoch 12/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7552 - mae: 1.5000 - val_loss: 0.7552 - val_mae: 1.5000\n",
      "Epoch 13/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7552 - mae: 1.5000 - val_loss: 0.7552 - val_mae: 1.5000\n",
      "Epoch 14/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7552 - mae: 1.5000 - val_loss: 0.7552 - val_mae: 1.5000\n",
      "Epoch 15/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7552 - mae: 1.5000 - val_loss: 0.7552 - val_mae: 1.5000\n",
      "Epoch 16/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7552 - mae: 1.5000 - val_loss: 0.7552 - val_mae: 1.5000\n",
      "Epoch 17/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7552 - mae: 1.5000 - val_loss: 0.7552 - val_mae: 1.5000\n",
      "Epoch 18/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7552 - mae: 1.5000 - val_loss: 0.7552 - val_mae: 1.5000\n",
      "Epoch 19/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7552 - mae: 1.5000 - val_loss: 0.7552 - val_mae: 1.5000\n",
      "Epoch 20/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7552 - mae: 1.5000 - val_loss: 0.7551 - val_mae: 1.5000\n",
      "Epoch 21/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7551 - mae: 1.5000 - val_loss: 0.7551 - val_mae: 1.5000\n",
      "Epoch 22/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7551 - mae: 1.5000 - val_loss: 0.7551 - val_mae: 1.5000\n",
      "Epoch 23/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7551 - mae: 1.5000 - val_loss: 0.7551 - val_mae: 1.5000\n",
      "Epoch 24/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7551 - mae: 1.5000 - val_loss: 0.7551 - val_mae: 1.5000\n",
      "Epoch 25/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7551 - mae: 1.5000 - val_loss: 0.7551 - val_mae: 1.5000\n",
      "Epoch 26/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7551 - mae: 1.5000 - val_loss: 0.7551 - val_mae: 1.5000\n",
      "Epoch 27/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7551 - mae: 1.5000 - val_loss: 0.7551 - val_mae: 1.5000\n",
      "Epoch 28/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7551 - mae: 1.5000 - val_loss: 0.7551 - val_mae: 1.5000\n",
      "Epoch 29/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7551 - mae: 1.5000 - val_loss: 0.7551 - val_mae: 1.5000\n",
      "Epoch 30/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7551 - mae: 1.5000 - val_loss: 0.7551 - val_mae: 1.5000\n",
      "Epoch 31/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7551 - mae: 1.5000 - val_loss: 0.7551 - val_mae: 1.5000\n",
      "Epoch 32/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7551 - mae: 1.5000 - val_loss: 0.7551 - val_mae: 1.5000\n",
      "Epoch 33/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7551 - mae: 1.5000 - val_loss: 0.7551 - val_mae: 1.5000\n",
      "Epoch 34/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7551 - mae: 1.5000 - val_loss: 0.7551 - val_mae: 1.5000\n",
      "Epoch 35/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7551 - mae: 1.5000 - val_loss: 0.7550 - val_mae: 1.5000\n",
      "Epoch 36/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7550 - mae: 1.5000 - val_loss: 0.7550 - val_mae: 1.5000\n",
      "Epoch 37/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7550 - mae: 1.5000 - val_loss: 0.7550 - val_mae: 1.5000\n",
      "Epoch 38/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7550 - mae: 1.5000 - val_loss: 0.7550 - val_mae: 1.5000\n",
      "Epoch 39/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7550 - mae: 1.5000 - val_loss: 0.7550 - val_mae: 1.5000\n",
      "Epoch 40/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7550 - mae: 1.5000 - val_loss: 0.7550 - val_mae: 1.5000\n",
      "Epoch 41/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7550 - mae: 1.5000 - val_loss: 0.7550 - val_mae: 1.5000\n",
      "Epoch 42/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7550 - mae: 1.5000 - val_loss: 0.7550 - val_mae: 1.5000\n",
      "Epoch 43/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7550 - mae: 1.5000 - val_loss: 0.7550 - val_mae: 1.5000\n",
      "Epoch 44/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7550 - mae: 1.5000 - val_loss: 0.7550 - val_mae: 1.5000\n",
      "Epoch 45/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7550 - mae: 1.5000 - val_loss: 0.7550 - val_mae: 1.5000\n",
      "Epoch 46/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7550 - mae: 1.5000 - val_loss: 0.7550 - val_mae: 1.5000\n",
      "Epoch 47/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7550 - mae: 1.5000 - val_loss: 0.7550 - val_mae: 1.5000\n",
      "Epoch 48/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7550 - mae: 1.5000 - val_loss: 0.7550 - val_mae: 1.5000\n",
      "Epoch 49/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7550 - mae: 1.5000 - val_loss: 0.7550 - val_mae: 1.5000\n",
      "Epoch 50/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7550 - mae: 1.5000 - val_loss: 0.7549 - val_mae: 1.5000\n",
      "Epoch 51/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7549 - mae: 1.5000 - val_loss: 0.7549 - val_mae: 1.5000\n",
      "Epoch 52/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7549 - mae: 1.5000 - val_loss: 0.7549 - val_mae: 1.5000\n",
      "Epoch 53/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7549 - mae: 1.5000 - val_loss: 0.7549 - val_mae: 1.5000\n",
      "Epoch 54/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7549 - mae: 1.5000 - val_loss: 0.7549 - val_mae: 1.5000\n",
      "Epoch 55/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7549 - mae: 1.5000 - val_loss: 0.7549 - val_mae: 1.4999\n",
      "Epoch 56/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7549 - mae: 1.4999 - val_loss: 0.7549 - val_mae: 1.4999\n",
      "Epoch 57/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7549 - mae: 1.4999 - val_loss: 0.7549 - val_mae: 1.4999\n",
      "Epoch 58/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7549 - mae: 1.4999 - val_loss: 0.7549 - val_mae: 1.4999\n",
      "Epoch 59/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7549 - mae: 1.4999 - val_loss: 0.7549 - val_mae: 1.4999\n",
      "Epoch 60/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7549 - mae: 1.4999 - val_loss: 0.7549 - val_mae: 1.4999\n",
      "Epoch 61/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7549 - mae: 1.4999 - val_loss: 0.7549 - val_mae: 1.4999\n",
      "Epoch 62/600\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7549 - mae: 1.499 - 0s 40ms/step - loss: 0.7549 - mae: 1.4999 - val_loss: 0.7549 - val_mae: 1.4999\n",
      "Epoch 63/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7549 - mae: 1.4999 - val_loss: 0.7549 - val_mae: 1.4999\n",
      "Epoch 64/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7549 - mae: 1.4999 - val_loss: 0.7548 - val_mae: 1.4999\n",
      "Epoch 65/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7548 - mae: 1.4999 - val_loss: 0.7548 - val_mae: 1.4999\n",
      "Epoch 66/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7548 - mae: 1.4999 - val_loss: 0.7548 - val_mae: 1.4999\n",
      "Epoch 67/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7548 - mae: 1.4999 - val_loss: 0.7548 - val_mae: 1.4999\n",
      "Epoch 68/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7548 - mae: 1.4999 - val_loss: 0.7548 - val_mae: 1.4999\n",
      "Epoch 69/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7548 - mae: 1.4999 - val_loss: 0.7548 - val_mae: 1.4999\n",
      "Epoch 70/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7548 - mae: 1.4999 - val_loss: 0.7548 - val_mae: 1.4999\n",
      "Epoch 71/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7548 - mae: 1.4999 - val_loss: 0.7548 - val_mae: 1.4999\n",
      "Epoch 72/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7548 - mae: 1.4999 - val_loss: 0.7548 - val_mae: 1.4999\n",
      "Epoch 73/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7548 - mae: 1.4999 - val_loss: 0.7548 - val_mae: 1.4999\n",
      "Epoch 74/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7548 - mae: 1.4999 - val_loss: 0.7548 - val_mae: 1.4999\n",
      "Epoch 75/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7548 - mae: 1.4999 - val_loss: 0.7548 - val_mae: 1.4999\n",
      "Epoch 76/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7548 - mae: 1.4999 - val_loss: 0.7548 - val_mae: 1.4999\n",
      "Epoch 77/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7548 - mae: 1.4999 - val_loss: 0.7548 - val_mae: 1.4999\n",
      "Epoch 78/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7548 - mae: 1.4999 - val_loss: 0.7547 - val_mae: 1.4999\n",
      "Epoch 79/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7547 - mae: 1.4999 - val_loss: 0.7547 - val_mae: 1.4999\n",
      "Epoch 80/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7547 - mae: 1.4999 - val_loss: 0.7547 - val_mae: 1.4999\n",
      "Epoch 81/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7547 - mae: 1.4999 - val_loss: 0.7547 - val_mae: 1.4999\n",
      "Epoch 82/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7547 - mae: 1.4999 - val_loss: 0.7547 - val_mae: 1.4999\n",
      "Epoch 83/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7547 - mae: 1.4999 - val_loss: 0.7547 - val_mae: 1.4999\n",
      "Epoch 84/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7547 - mae: 1.4999 - val_loss: 0.7547 - val_mae: 1.4999\n",
      "Epoch 85/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7547 - mae: 1.4999 - val_loss: 0.7547 - val_mae: 1.4999\n",
      "Epoch 86/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7547 - mae: 1.4999 - val_loss: 0.7547 - val_mae: 1.4999\n",
      "Epoch 87/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7547 - mae: 1.4999 - val_loss: 0.7547 - val_mae: 1.4999\n",
      "Epoch 88/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7547 - mae: 1.4999 - val_loss: 0.7547 - val_mae: 1.4999\n",
      "Epoch 89/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7547 - mae: 1.4999 - val_loss: 0.7547 - val_mae: 1.4999\n",
      "Epoch 90/600\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7547 - mae: 1.499 - 0s 43ms/step - loss: 0.7547 - mae: 1.4999 - val_loss: 0.7547 - val_mae: 1.4999\n",
      "Epoch 91/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7547 - mae: 1.4999 - val_loss: 0.7547 - val_mae: 1.4999\n",
      "Epoch 92/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7547 - mae: 1.4999 - val_loss: 0.7546 - val_mae: 1.4999\n",
      "Epoch 93/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7546 - mae: 1.4999 - val_loss: 0.7546 - val_mae: 1.4999\n",
      "Epoch 94/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7546 - mae: 1.4999 - val_loss: 0.7546 - val_mae: 1.4999\n",
      "Epoch 95/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7546 - mae: 1.4999 - val_loss: 0.7546 - val_mae: 1.4999\n",
      "Epoch 96/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7546 - mae: 1.4999 - val_loss: 0.7546 - val_mae: 1.4999\n",
      "Epoch 97/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7546 - mae: 1.4999 - val_loss: 0.7546 - val_mae: 1.4999\n",
      "Epoch 98/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7546 - mae: 1.4999 - val_loss: 0.7546 - val_mae: 1.4999\n",
      "Epoch 99/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7546 - mae: 1.4999 - val_loss: 0.7546 - val_mae: 1.4999\n",
      "Epoch 100/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7546 - mae: 1.4999 - val_loss: 0.7546 - val_mae: 1.4999\n",
      "Epoch 101/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7546 - mae: 1.4999 - val_loss: 0.7546 - val_mae: 1.4999\n",
      "Epoch 102/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7546 - mae: 1.4999 - val_loss: 0.7546 - val_mae: 1.4999\n",
      "Epoch 103/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7546 - mae: 1.4999 - val_loss: 0.7546 - val_mae: 1.4999\n",
      "Epoch 104/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7546 - mae: 1.4999 - val_loss: 0.7546 - val_mae: 1.4999\n",
      "Epoch 105/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7546 - mae: 1.4999 - val_loss: 0.7546 - val_mae: 1.4999\n",
      "Epoch 106/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7546 - mae: 1.4999 - val_loss: 0.7545 - val_mae: 1.4999\n",
      "Epoch 107/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7545 - mae: 1.4999 - val_loss: 0.7545 - val_mae: 1.4999\n",
      "Epoch 108/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7545 - mae: 1.4999 - val_loss: 0.7545 - val_mae: 1.4999\n",
      "Epoch 109/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7545 - mae: 1.4999 - val_loss: 0.7545 - val_mae: 1.4999\n",
      "Epoch 110/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7545 - mae: 1.4999 - val_loss: 0.7545 - val_mae: 1.4999\n",
      "Epoch 111/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7545 - mae: 1.4999 - val_loss: 0.7545 - val_mae: 1.4999\n",
      "Epoch 112/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7545 - mae: 1.4999 - val_loss: 0.7545 - val_mae: 1.4999\n",
      "Epoch 113/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7545 - mae: 1.4999 - val_loss: 0.7545 - val_mae: 1.4999\n",
      "Epoch 114/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7545 - mae: 1.4999 - val_loss: 0.7545 - val_mae: 1.4999\n",
      "Epoch 115/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7545 - mae: 1.4999 - val_loss: 0.7545 - val_mae: 1.4999\n",
      "Epoch 116/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7545 - mae: 1.4999 - val_loss: 0.7545 - val_mae: 1.4999\n",
      "Epoch 117/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7545 - mae: 1.4999 - val_loss: 0.7545 - val_mae: 1.4999\n",
      "Epoch 118/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7545 - mae: 1.4999 - val_loss: 0.7545 - val_mae: 1.4999\n",
      "Epoch 119/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7545 - mae: 1.4999 - val_loss: 0.7545 - val_mae: 1.4999\n",
      "Epoch 120/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7545 - mae: 1.4999 - val_loss: 0.7544 - val_mae: 1.4999\n",
      "Epoch 121/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7544 - mae: 1.4999 - val_loss: 0.7544 - val_mae: 1.4999\n",
      "Epoch 122/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7544 - mae: 1.4999 - val_loss: 0.7544 - val_mae: 1.4999\n",
      "Epoch 123/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7544 - mae: 1.4999 - val_loss: 0.7544 - val_mae: 1.4999\n",
      "Epoch 124/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7544 - mae: 1.4999 - val_loss: 0.7544 - val_mae: 1.4999\n",
      "Epoch 125/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7544 - mae: 1.4999 - val_loss: 0.7544 - val_mae: 1.4999\n",
      "Epoch 126/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7544 - mae: 1.4999 - val_loss: 0.7544 - val_mae: 1.4999\n",
      "Epoch 127/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7544 - mae: 1.4999 - val_loss: 0.7544 - val_mae: 1.4999\n",
      "Epoch 128/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7544 - mae: 1.4999 - val_loss: 0.7544 - val_mae: 1.4999\n",
      "Epoch 129/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7544 - mae: 1.4999 - val_loss: 0.7544 - val_mae: 1.4999\n",
      "Epoch 130/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7544 - mae: 1.4999 - val_loss: 0.7544 - val_mae: 1.4999\n",
      "Epoch 131/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7544 - mae: 1.4999 - val_loss: 0.7544 - val_mae: 1.4999\n",
      "Epoch 132/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7544 - mae: 1.4999 - val_loss: 0.7544 - val_mae: 1.4999\n",
      "Epoch 133/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7544 - mae: 1.4999 - val_loss: 0.7543 - val_mae: 1.4999\n",
      "Epoch 134/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7543 - mae: 1.4999 - val_loss: 0.7543 - val_mae: 1.4999\n",
      "Epoch 135/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7543 - mae: 1.4999 - val_loss: 0.7543 - val_mae: 1.4999\n",
      "Epoch 136/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7543 - mae: 1.4999 - val_loss: 0.7543 - val_mae: 1.4999\n",
      "Epoch 137/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7543 - mae: 1.4999 - val_loss: 0.7543 - val_mae: 1.4999\n",
      "Epoch 138/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7543 - mae: 1.4999 - val_loss: 0.7543 - val_mae: 1.4999\n",
      "Epoch 139/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7543 - mae: 1.4999 - val_loss: 0.7543 - val_mae: 1.4999\n",
      "Epoch 140/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7543 - mae: 1.4999 - val_loss: 0.7543 - val_mae: 1.4999\n",
      "Epoch 141/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7543 - mae: 1.4999 - val_loss: 0.7543 - val_mae: 1.4999\n",
      "Epoch 142/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7543 - mae: 1.4999 - val_loss: 0.7543 - val_mae: 1.4999\n",
      "Epoch 143/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7543 - mae: 1.4999 - val_loss: 0.7543 - val_mae: 1.4999\n",
      "Epoch 144/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7543 - mae: 1.4999 - val_loss: 0.7543 - val_mae: 1.4999\n",
      "Epoch 145/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7543 - mae: 1.4999 - val_loss: 0.7543 - val_mae: 1.4999\n",
      "Epoch 146/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7543 - mae: 1.4999 - val_loss: 0.7543 - val_mae: 1.4999\n",
      "Epoch 147/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7543 - mae: 1.4999 - val_loss: 0.7542 - val_mae: 1.4999\n",
      "Epoch 148/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7542 - mae: 1.4999 - val_loss: 0.7542 - val_mae: 1.4999\n",
      "Epoch 149/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7542 - mae: 1.4999 - val_loss: 0.7542 - val_mae: 1.4999\n",
      "Epoch 150/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7542 - mae: 1.4999 - val_loss: 0.7542 - val_mae: 1.4999\n",
      "Epoch 151/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7542 - mae: 1.4999 - val_loss: 0.7542 - val_mae: 1.4999\n",
      "Epoch 152/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7542 - mae: 1.4999 - val_loss: 0.7542 - val_mae: 1.4999\n",
      "Epoch 153/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7542 - mae: 1.4999 - val_loss: 0.7542 - val_mae: 1.4999\n",
      "Epoch 154/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7542 - mae: 1.4999 - val_loss: 0.7542 - val_mae: 1.4999\n",
      "Epoch 155/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7542 - mae: 1.4999 - val_loss: 0.7542 - val_mae: 1.4999\n",
      "Epoch 156/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7542 - mae: 1.4999 - val_loss: 0.7542 - val_mae: 1.4998\n",
      "Epoch 157/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7542 - mae: 1.4998 - val_loss: 0.7542 - val_mae: 1.4998\n",
      "Epoch 158/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7542 - mae: 1.4998 - val_loss: 0.7542 - val_mae: 1.4998\n",
      "Epoch 159/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7542 - mae: 1.4998 - val_loss: 0.7542 - val_mae: 1.4998\n",
      "Epoch 160/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7542 - mae: 1.4998 - val_loss: 0.7541 - val_mae: 1.4998\n",
      "Epoch 161/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7541 - mae: 1.4998 - val_loss: 0.7541 - val_mae: 1.4998\n",
      "Epoch 162/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7541 - mae: 1.4998 - val_loss: 0.7541 - val_mae: 1.4998\n",
      "Epoch 163/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7541 - mae: 1.4998 - val_loss: 0.7541 - val_mae: 1.4998\n",
      "Epoch 164/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7541 - mae: 1.4998 - val_loss: 0.7541 - val_mae: 1.4998\n",
      "Epoch 165/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7541 - mae: 1.4998 - val_loss: 0.7541 - val_mae: 1.4998\n",
      "Epoch 166/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7541 - mae: 1.4998 - val_loss: 0.7541 - val_mae: 1.4998\n",
      "Epoch 167/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7541 - mae: 1.4998 - val_loss: 0.7541 - val_mae: 1.4998\n",
      "Epoch 168/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7541 - mae: 1.4998 - val_loss: 0.7541 - val_mae: 1.4998\n",
      "Epoch 169/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7541 - mae: 1.4998 - val_loss: 0.7541 - val_mae: 1.4998\n",
      "Epoch 170/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7541 - mae: 1.4998 - val_loss: 0.7541 - val_mae: 1.4998\n",
      "Epoch 171/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7541 - mae: 1.4998 - val_loss: 0.7541 - val_mae: 1.4998\n",
      "Epoch 172/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7541 - mae: 1.4998 - val_loss: 0.7541 - val_mae: 1.4998\n",
      "Epoch 173/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7541 - mae: 1.4998 - val_loss: 0.7540 - val_mae: 1.4998\n",
      "Epoch 174/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7540 - mae: 1.4998 - val_loss: 0.7540 - val_mae: 1.4998\n",
      "Epoch 175/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7540 - mae: 1.4998 - val_loss: 0.7540 - val_mae: 1.4998\n",
      "Epoch 176/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7540 - mae: 1.4998 - val_loss: 0.7540 - val_mae: 1.4998\n",
      "Epoch 177/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7540 - mae: 1.4998 - val_loss: 0.7540 - val_mae: 1.4998\n",
      "Epoch 178/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7540 - mae: 1.4998 - val_loss: 0.7540 - val_mae: 1.4998\n",
      "Epoch 179/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7540 - mae: 1.4998 - val_loss: 0.7540 - val_mae: 1.4998\n",
      "Epoch 180/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7540 - mae: 1.4998 - val_loss: 0.7540 - val_mae: 1.4998\n",
      "Epoch 181/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7540 - mae: 1.4998 - val_loss: 0.7540 - val_mae: 1.4998\n",
      "Epoch 182/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7540 - mae: 1.4998 - val_loss: 0.7540 - val_mae: 1.4998\n",
      "Epoch 183/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7540 - mae: 1.4998 - val_loss: 0.7540 - val_mae: 1.4998\n",
      "Epoch 184/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7540 - mae: 1.4998 - val_loss: 0.7540 - val_mae: 1.4998\n",
      "Epoch 185/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7540 - mae: 1.4998 - val_loss: 0.7540 - val_mae: 1.4998\n",
      "Epoch 186/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7540 - mae: 1.4998 - val_loss: 0.7539 - val_mae: 1.4998\n",
      "Epoch 187/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7539 - mae: 1.4998 - val_loss: 0.7539 - val_mae: 1.4998\n",
      "Epoch 188/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7539 - mae: 1.4998 - val_loss: 0.7539 - val_mae: 1.4998\n",
      "Epoch 189/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7539 - mae: 1.4998 - val_loss: 0.7539 - val_mae: 1.4998\n",
      "Epoch 190/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7539 - mae: 1.4998 - val_loss: 0.7539 - val_mae: 1.4998\n",
      "Epoch 191/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7539 - mae: 1.4998 - val_loss: 0.7539 - val_mae: 1.4998\n",
      "Epoch 192/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7539 - mae: 1.4998 - val_loss: 0.7539 - val_mae: 1.4998\n",
      "Epoch 193/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7539 - mae: 1.4998 - val_loss: 0.7539 - val_mae: 1.4998\n",
      "Epoch 194/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7539 - mae: 1.4998 - val_loss: 0.7539 - val_mae: 1.4998\n",
      "Epoch 195/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7539 - mae: 1.4998 - val_loss: 0.7539 - val_mae: 1.4998\n",
      "Epoch 196/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7539 - mae: 1.4998 - val_loss: 0.7539 - val_mae: 1.4998\n",
      "Epoch 197/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7539 - mae: 1.4998 - val_loss: 0.7539 - val_mae: 1.4998\n",
      "Epoch 198/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7539 - mae: 1.4998 - val_loss: 0.7539 - val_mae: 1.4998\n",
      "Epoch 199/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7539 - mae: 1.4998 - val_loss: 0.7538 - val_mae: 1.4998\n",
      "Epoch 200/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7538 - mae: 1.4998 - val_loss: 0.7538 - val_mae: 1.4998\n",
      "Epoch 201/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7538 - mae: 1.4998 - val_loss: 0.7538 - val_mae: 1.4998\n",
      "Epoch 202/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7538 - mae: 1.4998 - val_loss: 0.7538 - val_mae: 1.4998\n",
      "Epoch 203/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7538 - mae: 1.4998 - val_loss: 0.7538 - val_mae: 1.4998\n",
      "Epoch 204/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7538 - mae: 1.4998 - val_loss: 0.7538 - val_mae: 1.4998\n",
      "Epoch 205/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7538 - mae: 1.4998 - val_loss: 0.7538 - val_mae: 1.4998\n",
      "Epoch 206/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7538 - mae: 1.4998 - val_loss: 0.7538 - val_mae: 1.4998\n",
      "Epoch 207/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7538 - mae: 1.4998 - val_loss: 0.7538 - val_mae: 1.4998\n",
      "Epoch 208/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7538 - mae: 1.4998 - val_loss: 0.7538 - val_mae: 1.4998\n",
      "Epoch 209/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7538 - mae: 1.4998 - val_loss: 0.7538 - val_mae: 1.4998\n",
      "Epoch 210/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7538 - mae: 1.4998 - val_loss: 0.7538 - val_mae: 1.4998\n",
      "Epoch 211/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7538 - mae: 1.4998 - val_loss: 0.7538 - val_mae: 1.4998\n",
      "Epoch 212/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7538 - mae: 1.4998 - val_loss: 0.7537 - val_mae: 1.4998\n",
      "Epoch 213/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7537 - mae: 1.4998 - val_loss: 0.7537 - val_mae: 1.4998\n",
      "Epoch 214/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7537 - mae: 1.4998 - val_loss: 0.7537 - val_mae: 1.4998\n",
      "Epoch 215/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7537 - mae: 1.4998 - val_loss: 0.7537 - val_mae: 1.4998\n",
      "Epoch 216/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7537 - mae: 1.4998 - val_loss: 0.7537 - val_mae: 1.4998\n",
      "Epoch 217/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7537 - mae: 1.4998 - val_loss: 0.7537 - val_mae: 1.4998\n",
      "Epoch 218/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7537 - mae: 1.4998 - val_loss: 0.7537 - val_mae: 1.4998\n",
      "Epoch 219/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7537 - mae: 1.4998 - val_loss: 0.7537 - val_mae: 1.4998\n",
      "Epoch 220/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7537 - mae: 1.4998 - val_loss: 0.7537 - val_mae: 1.4998\n",
      "Epoch 221/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7537 - mae: 1.4998 - val_loss: 0.7537 - val_mae: 1.4998\n",
      "Epoch 222/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7537 - mae: 1.4998 - val_loss: 0.7537 - val_mae: 1.4998\n",
      "Epoch 223/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7537 - mae: 1.4998 - val_loss: 0.7537 - val_mae: 1.4998\n",
      "Epoch 224/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7537 - mae: 1.4998 - val_loss: 0.7536 - val_mae: 1.4998\n",
      "Epoch 225/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7536 - mae: 1.4998 - val_loss: 0.7536 - val_mae: 1.4998\n",
      "Epoch 226/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7536 - mae: 1.4998 - val_loss: 0.7536 - val_mae: 1.4998\n",
      "Epoch 227/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7536 - mae: 1.4998 - val_loss: 0.7536 - val_mae: 1.4998\n",
      "Epoch 228/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7536 - mae: 1.4998 - val_loss: 0.7536 - val_mae: 1.4998\n",
      "Epoch 229/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7536 - mae: 1.4998 - val_loss: 0.7536 - val_mae: 1.4998\n",
      "Epoch 230/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7536 - mae: 1.4998 - val_loss: 0.7536 - val_mae: 1.4998\n",
      "Epoch 231/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7536 - mae: 1.4998 - val_loss: 0.7536 - val_mae: 1.4998\n",
      "Epoch 232/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7536 - mae: 1.4998 - val_loss: 0.7536 - val_mae: 1.4998\n",
      "Epoch 233/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7536 - mae: 1.4998 - val_loss: 0.7536 - val_mae: 1.4998\n",
      "Epoch 234/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7536 - mae: 1.4998 - val_loss: 0.7536 - val_mae: 1.4998\n",
      "Epoch 235/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7536 - mae: 1.4998 - val_loss: 0.7536 - val_mae: 1.4998\n",
      "Epoch 236/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7536 - mae: 1.4998 - val_loss: 0.7536 - val_mae: 1.4998\n",
      "Epoch 237/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7536 - mae: 1.4998 - val_loss: 0.7535 - val_mae: 1.4998\n",
      "Epoch 238/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7535 - mae: 1.4998 - val_loss: 0.7535 - val_mae: 1.4998\n",
      "Epoch 239/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7535 - mae: 1.4998 - val_loss: 0.7535 - val_mae: 1.4998\n",
      "Epoch 240/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7535 - mae: 1.4998 - val_loss: 0.7535 - val_mae: 1.4998\n",
      "Epoch 241/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7535 - mae: 1.4998 - val_loss: 0.7535 - val_mae: 1.4998\n",
      "Epoch 242/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7535 - mae: 1.4998 - val_loss: 0.7535 - val_mae: 1.4998\n",
      "Epoch 243/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7535 - mae: 1.4998 - val_loss: 0.7535 - val_mae: 1.4998\n",
      "Epoch 244/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7535 - mae: 1.4998 - val_loss: 0.7535 - val_mae: 1.4998\n",
      "Epoch 245/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7535 - mae: 1.4998 - val_loss: 0.7535 - val_mae: 1.4998\n",
      "Epoch 246/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7535 - mae: 1.4998 - val_loss: 0.7535 - val_mae: 1.4998\n",
      "Epoch 247/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7535 - mae: 1.4998 - val_loss: 0.7535 - val_mae: 1.4998\n",
      "Epoch 248/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7535 - mae: 1.4998 - val_loss: 0.7535 - val_mae: 1.4998\n",
      "Epoch 249/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7535 - mae: 1.4998 - val_loss: 0.7534 - val_mae: 1.4998\n",
      "Epoch 250/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7534 - mae: 1.4998 - val_loss: 0.7534 - val_mae: 1.4997\n",
      "Epoch 251/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7534 - mae: 1.4997 - val_loss: 0.7534 - val_mae: 1.4997\n",
      "Epoch 252/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7534 - mae: 1.4997 - val_loss: 0.7534 - val_mae: 1.4997\n",
      "Epoch 253/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7534 - mae: 1.4997 - val_loss: 0.7534 - val_mae: 1.4997\n",
      "Epoch 254/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7534 - mae: 1.4997 - val_loss: 0.7534 - val_mae: 1.4997\n",
      "Epoch 255/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7534 - mae: 1.4997 - val_loss: 0.7534 - val_mae: 1.4997\n",
      "Epoch 256/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7534 - mae: 1.4997 - val_loss: 0.7534 - val_mae: 1.4997\n",
      "Epoch 257/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7534 - mae: 1.4997 - val_loss: 0.7534 - val_mae: 1.4997\n",
      "Epoch 258/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7534 - mae: 1.4997 - val_loss: 0.7534 - val_mae: 1.4997\n",
      "Epoch 259/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7534 - mae: 1.4997 - val_loss: 0.7534 - val_mae: 1.4997\n",
      "Epoch 260/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7534 - mae: 1.4997 - val_loss: 0.7534 - val_mae: 1.4997\n",
      "Epoch 261/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7534 - mae: 1.4997 - val_loss: 0.7533 - val_mae: 1.4997\n",
      "Epoch 262/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7533 - mae: 1.4997 - val_loss: 0.7533 - val_mae: 1.4997\n",
      "Epoch 263/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7533 - mae: 1.4997 - val_loss: 0.7533 - val_mae: 1.4997\n",
      "Epoch 264/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7533 - mae: 1.4997 - val_loss: 0.7533 - val_mae: 1.4997\n",
      "Epoch 265/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7533 - mae: 1.4997 - val_loss: 0.7533 - val_mae: 1.4997\n",
      "Epoch 266/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7533 - mae: 1.4997 - val_loss: 0.7533 - val_mae: 1.4997\n",
      "Epoch 267/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7533 - mae: 1.4997 - val_loss: 0.7533 - val_mae: 1.4997\n",
      "Epoch 268/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7533 - mae: 1.4997 - val_loss: 0.7533 - val_mae: 1.4997\n",
      "Epoch 269/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7533 - mae: 1.4997 - val_loss: 0.7533 - val_mae: 1.4997\n",
      "Epoch 270/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7533 - mae: 1.4997 - val_loss: 0.7533 - val_mae: 1.4997\n",
      "Epoch 271/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7533 - mae: 1.4997 - val_loss: 0.7533 - val_mae: 1.4997\n",
      "Epoch 272/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7533 - mae: 1.4997 - val_loss: 0.7533 - val_mae: 1.4997\n",
      "Epoch 273/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7533 - mae: 1.4997 - val_loss: 0.7532 - val_mae: 1.4997\n",
      "Epoch 274/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7532 - mae: 1.4997 - val_loss: 0.7532 - val_mae: 1.4997\n",
      "Epoch 275/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7532 - mae: 1.4997 - val_loss: 0.7532 - val_mae: 1.4997\n",
      "Epoch 276/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7532 - mae: 1.4997 - val_loss: 0.7532 - val_mae: 1.4997\n",
      "Epoch 277/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7532 - mae: 1.4997 - val_loss: 0.7532 - val_mae: 1.4997\n",
      "Epoch 278/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7532 - mae: 1.4997 - val_loss: 0.7532 - val_mae: 1.4997\n",
      "Epoch 279/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7532 - mae: 1.4997 - val_loss: 0.7532 - val_mae: 1.4997\n",
      "Epoch 280/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7532 - mae: 1.4997 - val_loss: 0.7532 - val_mae: 1.4997\n",
      "Epoch 281/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7532 - mae: 1.4997 - val_loss: 0.7532 - val_mae: 1.4997\n",
      "Epoch 282/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7532 - mae: 1.4997 - val_loss: 0.7532 - val_mae: 1.4997\n",
      "Epoch 283/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7532 - mae: 1.4997 - val_loss: 0.7532 - val_mae: 1.4997\n",
      "Epoch 284/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7532 - mae: 1.4997 - val_loss: 0.7532 - val_mae: 1.4997\n",
      "Epoch 285/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7532 - mae: 1.4997 - val_loss: 0.7532 - val_mae: 1.4997\n",
      "Epoch 286/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7532 - mae: 1.4997 - val_loss: 0.7531 - val_mae: 1.4997\n",
      "Epoch 287/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7531 - mae: 1.4997 - val_loss: 0.7531 - val_mae: 1.4997\n",
      "Epoch 288/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7531 - mae: 1.4997 - val_loss: 0.7531 - val_mae: 1.4997\n",
      "Epoch 289/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7531 - mae: 1.4997 - val_loss: 0.7531 - val_mae: 1.4997\n",
      "Epoch 290/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7531 - mae: 1.4997 - val_loss: 0.7531 - val_mae: 1.4997\n",
      "Epoch 291/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7531 - mae: 1.4997 - val_loss: 0.7531 - val_mae: 1.4997\n",
      "Epoch 292/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7531 - mae: 1.4997 - val_loss: 0.7531 - val_mae: 1.4997\n",
      "Epoch 293/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7531 - mae: 1.4997 - val_loss: 0.7531 - val_mae: 1.4997\n",
      "Epoch 294/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7531 - mae: 1.4997 - val_loss: 0.7531 - val_mae: 1.4997\n",
      "Epoch 295/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7531 - mae: 1.4997 - val_loss: 0.7531 - val_mae: 1.4997\n",
      "Epoch 296/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7531 - mae: 1.4997 - val_loss: 0.7531 - val_mae: 1.4997\n",
      "Epoch 297/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7531 - mae: 1.4997 - val_loss: 0.7531 - val_mae: 1.4997\n",
      "Epoch 298/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7531 - mae: 1.4997 - val_loss: 0.7530 - val_mae: 1.4997\n",
      "Epoch 299/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7530 - mae: 1.4997 - val_loss: 0.7530 - val_mae: 1.4997\n",
      "Epoch 300/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7530 - mae: 1.4997 - val_loss: 0.7530 - val_mae: 1.4997\n",
      "Epoch 301/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7530 - mae: 1.4997 - val_loss: 0.7530 - val_mae: 1.4997\n",
      "Epoch 302/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7530 - mae: 1.4997 - val_loss: 0.7530 - val_mae: 1.4997\n",
      "Epoch 303/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7530 - mae: 1.4997 - val_loss: 0.7530 - val_mae: 1.4997\n",
      "Epoch 304/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7530 - mae: 1.4997 - val_loss: 0.7530 - val_mae: 1.4997\n",
      "Epoch 305/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7530 - mae: 1.4997 - val_loss: 0.7530 - val_mae: 1.4997\n",
      "Epoch 306/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7530 - mae: 1.4997 - val_loss: 0.7530 - val_mae: 1.4997\n",
      "Epoch 307/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7530 - mae: 1.4997 - val_loss: 0.7530 - val_mae: 1.4997\n",
      "Epoch 308/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7530 - mae: 1.4997 - val_loss: 0.7530 - val_mae: 1.4997\n",
      "Epoch 309/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7530 - mae: 1.4997 - val_loss: 0.7529 - val_mae: 1.4997\n",
      "Epoch 310/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7529 - mae: 1.4997 - val_loss: 0.7529 - val_mae: 1.4997\n",
      "Epoch 311/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7529 - mae: 1.4997 - val_loss: 0.7529 - val_mae: 1.4997\n",
      "Epoch 312/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7529 - mae: 1.4997 - val_loss: 0.7529 - val_mae: 1.4997\n",
      "Epoch 313/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7529 - mae: 1.4997 - val_loss: 0.7529 - val_mae: 1.4997\n",
      "Epoch 314/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7529 - mae: 1.4997 - val_loss: 0.7529 - val_mae: 1.4997\n",
      "Epoch 315/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7529 - mae: 1.4997 - val_loss: 0.7529 - val_mae: 1.4997\n",
      "Epoch 316/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7529 - mae: 1.4997 - val_loss: 0.7529 - val_mae: 1.4997\n",
      "Epoch 317/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7529 - mae: 1.4997 - val_loss: 0.7529 - val_mae: 1.4997\n",
      "Epoch 318/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7529 - mae: 1.4997 - val_loss: 0.7529 - val_mae: 1.4997\n",
      "Epoch 319/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7529 - mae: 1.4997 - val_loss: 0.7529 - val_mae: 1.4997\n",
      "Epoch 320/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7529 - mae: 1.4997 - val_loss: 0.7529 - val_mae: 1.4997\n",
      "Epoch 321/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7529 - mae: 1.4997 - val_loss: 0.7528 - val_mae: 1.4997\n",
      "Epoch 322/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7528 - mae: 1.4997 - val_loss: 0.7528 - val_mae: 1.4997\n",
      "Epoch 323/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7528 - mae: 1.4997 - val_loss: 0.7528 - val_mae: 1.4997\n",
      "Epoch 324/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7528 - mae: 1.4997 - val_loss: 0.7528 - val_mae: 1.4997\n",
      "Epoch 325/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7528 - mae: 1.4997 - val_loss: 0.7528 - val_mae: 1.4997\n",
      "Epoch 326/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7528 - mae: 1.4997 - val_loss: 0.7528 - val_mae: 1.4997\n",
      "Epoch 327/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7528 - mae: 1.4997 - val_loss: 0.7528 - val_mae: 1.4997\n",
      "Epoch 328/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7528 - mae: 1.4997 - val_loss: 0.7528 - val_mae: 1.4997\n",
      "Epoch 329/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7528 - mae: 1.4997 - val_loss: 0.7528 - val_mae: 1.4997\n",
      "Epoch 330/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7528 - mae: 1.4997 - val_loss: 0.7528 - val_mae: 1.4997\n",
      "Epoch 331/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7528 - mae: 1.4997 - val_loss: 0.7528 - val_mae: 1.4997\n",
      "Epoch 332/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7528 - mae: 1.4997 - val_loss: 0.7528 - val_mae: 1.4997\n",
      "Epoch 333/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7528 - mae: 1.4997 - val_loss: 0.7527 - val_mae: 1.4997\n",
      "Epoch 334/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7527 - mae: 1.4997 - val_loss: 0.7527 - val_mae: 1.4997\n",
      "Epoch 335/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7527 - mae: 1.4997 - val_loss: 0.7527 - val_mae: 1.4997\n",
      "Epoch 336/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7527 - mae: 1.4997 - val_loss: 0.7527 - val_mae: 1.4997\n",
      "Epoch 337/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7527 - mae: 1.4997 - val_loss: 0.7527 - val_mae: 1.4996\n",
      "Epoch 338/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7527 - mae: 1.4996 - val_loss: 0.7527 - val_mae: 1.4996\n",
      "Epoch 339/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7527 - mae: 1.4996 - val_loss: 0.7527 - val_mae: 1.4996\n",
      "Epoch 340/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7527 - mae: 1.4996 - val_loss: 0.7527 - val_mae: 1.4996\n",
      "Epoch 341/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7527 - mae: 1.4996 - val_loss: 0.7527 - val_mae: 1.4996\n",
      "Epoch 342/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7527 - mae: 1.4996 - val_loss: 0.7527 - val_mae: 1.4996\n",
      "Epoch 343/600\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7527 - mae: 1.499 - 0s 44ms/step - loss: 0.7527 - mae: 1.4996 - val_loss: 0.7527 - val_mae: 1.4996\n",
      "Epoch 344/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7527 - mae: 1.4996 - val_loss: 0.7527 - val_mae: 1.4996\n",
      "Epoch 345/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7527 - mae: 1.4996 - val_loss: 0.7526 - val_mae: 1.4996\n",
      "Epoch 346/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7526 - mae: 1.4996 - val_loss: 0.7526 - val_mae: 1.4996\n",
      "Epoch 347/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7526 - mae: 1.4996 - val_loss: 0.7526 - val_mae: 1.4996\n",
      "Epoch 348/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7526 - mae: 1.4996 - val_loss: 0.7526 - val_mae: 1.4996\n",
      "Epoch 349/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7526 - mae: 1.4996 - val_loss: 0.7526 - val_mae: 1.4996\n",
      "Epoch 350/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7526 - mae: 1.4996 - val_loss: 0.7526 - val_mae: 1.4996\n",
      "Epoch 351/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7526 - mae: 1.4996 - val_loss: 0.7526 - val_mae: 1.4996\n",
      "Epoch 352/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7526 - mae: 1.4996 - val_loss: 0.7526 - val_mae: 1.4996\n",
      "Epoch 353/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7526 - mae: 1.4996 - val_loss: 0.7526 - val_mae: 1.4996\n",
      "Epoch 354/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7526 - mae: 1.4996 - val_loss: 0.7526 - val_mae: 1.4996\n",
      "Epoch 355/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7526 - mae: 1.4996 - val_loss: 0.7526 - val_mae: 1.4996\n",
      "Epoch 356/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7526 - mae: 1.4996 - val_loss: 0.7525 - val_mae: 1.4996\n",
      "Epoch 357/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7525 - mae: 1.4996 - val_loss: 0.7525 - val_mae: 1.4996\n",
      "Epoch 358/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7525 - mae: 1.4996 - val_loss: 0.7525 - val_mae: 1.4996\n",
      "Epoch 359/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7525 - mae: 1.4996 - val_loss: 0.7525 - val_mae: 1.4996\n",
      "Epoch 360/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7525 - mae: 1.4996 - val_loss: 0.7525 - val_mae: 1.4996\n",
      "Epoch 361/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7525 - mae: 1.4996 - val_loss: 0.7525 - val_mae: 1.4996\n",
      "Epoch 362/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7525 - mae: 1.4996 - val_loss: 0.7525 - val_mae: 1.4996\n",
      "Epoch 363/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7525 - mae: 1.4996 - val_loss: 0.7525 - val_mae: 1.4996\n",
      "Epoch 364/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7525 - mae: 1.4996 - val_loss: 0.7525 - val_mae: 1.4996\n",
      "Epoch 365/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7525 - mae: 1.4996 - val_loss: 0.7525 - val_mae: 1.4996\n",
      "Epoch 366/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7525 - mae: 1.4996 - val_loss: 0.7525 - val_mae: 1.4996\n",
      "Epoch 367/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7525 - mae: 1.4996 - val_loss: 0.7525 - val_mae: 1.4996\n",
      "Epoch 368/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7525 - mae: 1.4996 - val_loss: 0.7524 - val_mae: 1.4996\n",
      "Epoch 369/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7524 - mae: 1.4996 - val_loss: 0.7524 - val_mae: 1.4996\n",
      "Epoch 370/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7524 - mae: 1.4996 - val_loss: 0.7524 - val_mae: 1.4996\n",
      "Epoch 371/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7524 - mae: 1.4996 - val_loss: 0.7524 - val_mae: 1.4996\n",
      "Epoch 372/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7524 - mae: 1.4996 - val_loss: 0.7524 - val_mae: 1.4996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 373/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7524 - mae: 1.4996 - val_loss: 0.7524 - val_mae: 1.4996\n",
      "Epoch 374/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7524 - mae: 1.4996 - val_loss: 0.7524 - val_mae: 1.4996\n",
      "Epoch 375/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7524 - mae: 1.4996 - val_loss: 0.7524 - val_mae: 1.4996\n",
      "Epoch 376/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7524 - mae: 1.4996 - val_loss: 0.7524 - val_mae: 1.4996\n",
      "Epoch 377/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7524 - mae: 1.4996 - val_loss: 0.7524 - val_mae: 1.4996\n",
      "Epoch 378/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7524 - mae: 1.4996 - val_loss: 0.7524 - val_mae: 1.4996\n",
      "Epoch 379/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7524 - mae: 1.4996 - val_loss: 0.7523 - val_mae: 1.4996\n",
      "Epoch 380/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7523 - mae: 1.4996 - val_loss: 0.7523 - val_mae: 1.4996\n",
      "Epoch 381/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7523 - mae: 1.4996 - val_loss: 0.7523 - val_mae: 1.4996\n",
      "Epoch 382/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7523 - mae: 1.4996 - val_loss: 0.7523 - val_mae: 1.4996\n",
      "Epoch 383/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7523 - mae: 1.4996 - val_loss: 0.7523 - val_mae: 1.4996\n",
      "Epoch 384/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7523 - mae: 1.4996 - val_loss: 0.7523 - val_mae: 1.4996\n",
      "Epoch 385/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7523 - mae: 1.4996 - val_loss: 0.7523 - val_mae: 1.4996\n",
      "Epoch 386/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7523 - mae: 1.4996 - val_loss: 0.7523 - val_mae: 1.4996\n",
      "Epoch 387/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7523 - mae: 1.4996 - val_loss: 0.7523 - val_mae: 1.4996\n",
      "Epoch 388/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7523 - mae: 1.4996 - val_loss: 0.7523 - val_mae: 1.4996\n",
      "Epoch 389/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7523 - mae: 1.4996 - val_loss: 0.7523 - val_mae: 1.4996\n",
      "Epoch 390/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7523 - mae: 1.4996 - val_loss: 0.7523 - val_mae: 1.4996\n",
      "Epoch 391/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7523 - mae: 1.4996 - val_loss: 0.7522 - val_mae: 1.4996\n",
      "Epoch 392/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7522 - mae: 1.4996 - val_loss: 0.7522 - val_mae: 1.4996\n",
      "Epoch 393/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7522 - mae: 1.4996 - val_loss: 0.7522 - val_mae: 1.4996\n",
      "Epoch 394/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7522 - mae: 1.4996 - val_loss: 0.7522 - val_mae: 1.4996\n",
      "Epoch 395/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7522 - mae: 1.4996 - val_loss: 0.7522 - val_mae: 1.4996\n",
      "Epoch 396/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7522 - mae: 1.4996 - val_loss: 0.7522 - val_mae: 1.4996\n",
      "Epoch 397/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7522 - mae: 1.4996 - val_loss: 0.7522 - val_mae: 1.4996\n",
      "Epoch 398/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7522 - mae: 1.4996 - val_loss: 0.7522 - val_mae: 1.4996\n",
      "Epoch 399/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7522 - mae: 1.4996 - val_loss: 0.7522 - val_mae: 1.4996\n",
      "Epoch 400/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7522 - mae: 1.4996 - val_loss: 0.7522 - val_mae: 1.4996\n",
      "Epoch 401/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7522 - mae: 1.4996 - val_loss: 0.7522 - val_mae: 1.4996\n",
      "Epoch 402/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7522 - mae: 1.4996 - val_loss: 0.7521 - val_mae: 1.4996\n",
      "Epoch 403/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7521 - mae: 1.4996 - val_loss: 0.7521 - val_mae: 1.4996\n",
      "Epoch 404/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7521 - mae: 1.4996 - val_loss: 0.7521 - val_mae: 1.4996\n",
      "Epoch 405/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7521 - mae: 1.4996 - val_loss: 0.7521 - val_mae: 1.4996\n",
      "Epoch 406/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7521 - mae: 1.4996 - val_loss: 0.7521 - val_mae: 1.4996\n",
      "Epoch 407/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7521 - mae: 1.4996 - val_loss: 0.7521 - val_mae: 1.4996\n",
      "Epoch 408/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7521 - mae: 1.4996 - val_loss: 0.7521 - val_mae: 1.4996\n",
      "Epoch 409/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7521 - mae: 1.4996 - val_loss: 0.7521 - val_mae: 1.4996\n",
      "Epoch 410/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7521 - mae: 1.4996 - val_loss: 0.7521 - val_mae: 1.4996\n",
      "Epoch 411/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7521 - mae: 1.4996 - val_loss: 0.7521 - val_mae: 1.4996\n",
      "Epoch 412/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7521 - mae: 1.4996 - val_loss: 0.7521 - val_mae: 1.4996\n",
      "Epoch 413/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7521 - mae: 1.4996 - val_loss: 0.7520 - val_mae: 1.4996\n",
      "Epoch 414/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7520 - mae: 1.4996 - val_loss: 0.7520 - val_mae: 1.4996\n",
      "Epoch 415/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7520 - mae: 1.4996 - val_loss: 0.7520 - val_mae: 1.4996\n",
      "Epoch 416/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7520 - mae: 1.4996 - val_loss: 0.7520 - val_mae: 1.4996\n",
      "Epoch 417/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7520 - mae: 1.4996 - val_loss: 0.7520 - val_mae: 1.4996\n",
      "Epoch 418/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7520 - mae: 1.4996 - val_loss: 0.7520 - val_mae: 1.4996\n",
      "Epoch 419/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7520 - mae: 1.4996 - val_loss: 0.7520 - val_mae: 1.4996\n",
      "Epoch 420/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7520 - mae: 1.4996 - val_loss: 0.7520 - val_mae: 1.4995\n",
      "Epoch 421/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7520 - mae: 1.4995 - val_loss: 0.7520 - val_mae: 1.4995\n",
      "Epoch 422/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7520 - mae: 1.4995 - val_loss: 0.7520 - val_mae: 1.4995\n",
      "Epoch 423/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7520 - mae: 1.4995 - val_loss: 0.7520 - val_mae: 1.4995\n",
      "Epoch 424/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7520 - mae: 1.4995 - val_loss: 0.7519 - val_mae: 1.4995\n",
      "Epoch 425/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7519 - mae: 1.4995 - val_loss: 0.7519 - val_mae: 1.4995\n",
      "Epoch 426/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7519 - mae: 1.4995 - val_loss: 0.7519 - val_mae: 1.4995\n",
      "Epoch 427/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7519 - mae: 1.4995 - val_loss: 0.7519 - val_mae: 1.4995\n",
      "Epoch 428/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7519 - mae: 1.4995 - val_loss: 0.7519 - val_mae: 1.4995\n",
      "Epoch 429/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7519 - mae: 1.4995 - val_loss: 0.7519 - val_mae: 1.4995\n",
      "Epoch 430/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7519 - mae: 1.4995 - val_loss: 0.7519 - val_mae: 1.4995\n",
      "Epoch 431/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7519 - mae: 1.4995 - val_loss: 0.7519 - val_mae: 1.4995\n",
      "Epoch 432/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7519 - mae: 1.4995 - val_loss: 0.7519 - val_mae: 1.4995\n",
      "Epoch 433/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7519 - mae: 1.4995 - val_loss: 0.7519 - val_mae: 1.4995\n",
      "Epoch 434/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7519 - mae: 1.4995 - val_loss: 0.7519 - val_mae: 1.4995\n",
      "Epoch 435/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7519 - mae: 1.4995 - val_loss: 0.7518 - val_mae: 1.4995\n",
      "Epoch 436/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7518 - mae: 1.4995 - val_loss: 0.7518 - val_mae: 1.4995\n",
      "Epoch 437/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7518 - mae: 1.4995 - val_loss: 0.7518 - val_mae: 1.4995\n",
      "Epoch 438/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7518 - mae: 1.4995 - val_loss: 0.7518 - val_mae: 1.4995\n",
      "Epoch 439/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7518 - mae: 1.4995 - val_loss: 0.7518 - val_mae: 1.4995\n",
      "Epoch 440/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7518 - mae: 1.4995 - val_loss: 0.7518 - val_mae: 1.4995\n",
      "Epoch 441/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7518 - mae: 1.4995 - val_loss: 0.7518 - val_mae: 1.4995\n",
      "Epoch 442/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7518 - mae: 1.4995 - val_loss: 0.7518 - val_mae: 1.4995\n",
      "Epoch 443/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7518 - mae: 1.4995 - val_loss: 0.7518 - val_mae: 1.4995\n",
      "Epoch 444/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7518 - mae: 1.4995 - val_loss: 0.7518 - val_mae: 1.4995\n",
      "Epoch 445/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7518 - mae: 1.4995 - val_loss: 0.7518 - val_mae: 1.4995\n",
      "Epoch 446/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7518 - mae: 1.4995 - val_loss: 0.7517 - val_mae: 1.4995\n",
      "Epoch 447/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7517 - mae: 1.4995 - val_loss: 0.7517 - val_mae: 1.4995\n",
      "Epoch 448/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7517 - mae: 1.4995 - val_loss: 0.7517 - val_mae: 1.4995\n",
      "Epoch 449/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7517 - mae: 1.4995 - val_loss: 0.7517 - val_mae: 1.4995\n",
      "Epoch 450/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7517 - mae: 1.4995 - val_loss: 0.7517 - val_mae: 1.4995\n",
      "Epoch 451/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7517 - mae: 1.4995 - val_loss: 0.7517 - val_mae: 1.4995\n",
      "Epoch 452/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7517 - mae: 1.4995 - val_loss: 0.7517 - val_mae: 1.4995\n",
      "Epoch 453/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7517 - mae: 1.4995 - val_loss: 0.7517 - val_mae: 1.4995\n",
      "Epoch 454/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7517 - mae: 1.4995 - val_loss: 0.7517 - val_mae: 1.4995\n",
      "Epoch 455/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7517 - mae: 1.4995 - val_loss: 0.7517 - val_mae: 1.4995\n",
      "Epoch 456/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7517 - mae: 1.4995 - val_loss: 0.7517 - val_mae: 1.4995\n",
      "Epoch 457/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7517 - mae: 1.4995 - val_loss: 0.7516 - val_mae: 1.4995\n",
      "Epoch 458/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7516 - mae: 1.4995 - val_loss: 0.7516 - val_mae: 1.4995\n",
      "Epoch 459/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7516 - mae: 1.4995 - val_loss: 0.7516 - val_mae: 1.4995\n",
      "Epoch 460/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7516 - mae: 1.4995 - val_loss: 0.7516 - val_mae: 1.4995\n",
      "Epoch 461/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7516 - mae: 1.4995 - val_loss: 0.7516 - val_mae: 1.4995\n",
      "Epoch 462/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7516 - mae: 1.4995 - val_loss: 0.7516 - val_mae: 1.4995\n",
      "Epoch 463/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7516 - mae: 1.4995 - val_loss: 0.7516 - val_mae: 1.4995\n",
      "Epoch 464/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7516 - mae: 1.4995 - val_loss: 0.7516 - val_mae: 1.4995\n",
      "Epoch 465/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7516 - mae: 1.4995 - val_loss: 0.7516 - val_mae: 1.4995\n",
      "Epoch 466/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7516 - mae: 1.4995 - val_loss: 0.7516 - val_mae: 1.4995\n",
      "Epoch 467/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7516 - mae: 1.4995 - val_loss: 0.7516 - val_mae: 1.4995\n",
      "Epoch 468/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7516 - mae: 1.4995 - val_loss: 0.7515 - val_mae: 1.4995\n",
      "Epoch 469/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7515 - mae: 1.4995 - val_loss: 0.7515 - val_mae: 1.4995\n",
      "Epoch 470/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7515 - mae: 1.4995 - val_loss: 0.7515 - val_mae: 1.4995\n",
      "Epoch 471/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7515 - mae: 1.4995 - val_loss: 0.7515 - val_mae: 1.4995\n",
      "Epoch 472/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7515 - mae: 1.4995 - val_loss: 0.7515 - val_mae: 1.4995\n",
      "Epoch 473/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7515 - mae: 1.4995 - val_loss: 0.7515 - val_mae: 1.4995\n",
      "Epoch 474/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7515 - mae: 1.4995 - val_loss: 0.7515 - val_mae: 1.4995\n",
      "Epoch 475/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7515 - mae: 1.4995 - val_loss: 0.7515 - val_mae: 1.4995\n",
      "Epoch 476/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7515 - mae: 1.4995 - val_loss: 0.7515 - val_mae: 1.4995\n",
      "Epoch 477/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7515 - mae: 1.4995 - val_loss: 0.7515 - val_mae: 1.4995\n",
      "Epoch 478/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7515 - mae: 1.4995 - val_loss: 0.7515 - val_mae: 1.4995\n",
      "Epoch 479/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7515 - mae: 1.4995 - val_loss: 0.7514 - val_mae: 1.4995\n",
      "Epoch 480/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7514 - mae: 1.4995 - val_loss: 0.7514 - val_mae: 1.4995\n",
      "Epoch 481/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7514 - mae: 1.4995 - val_loss: 0.7514 - val_mae: 1.4995\n",
      "Epoch 482/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7514 - mae: 1.4995 - val_loss: 0.7514 - val_mae: 1.4995\n",
      "Epoch 483/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7514 - mae: 1.4995 - val_loss: 0.7514 - val_mae: 1.4995\n",
      "Epoch 484/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7514 - mae: 1.4995 - val_loss: 0.7514 - val_mae: 1.4995\n",
      "Epoch 485/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7514 - mae: 1.4995 - val_loss: 0.7514 - val_mae: 1.4995\n",
      "Epoch 486/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7514 - mae: 1.4995 - val_loss: 0.7514 - val_mae: 1.4995\n",
      "Epoch 487/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7514 - mae: 1.4995 - val_loss: 0.7514 - val_mae: 1.4995\n",
      "Epoch 488/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7514 - mae: 1.4995 - val_loss: 0.7514 - val_mae: 1.4995\n",
      "Epoch 489/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7514 - mae: 1.4995 - val_loss: 0.7514 - val_mae: 1.4995\n",
      "Epoch 490/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7514 - mae: 1.4995 - val_loss: 0.7513 - val_mae: 1.4995\n",
      "Epoch 491/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7513 - mae: 1.4995 - val_loss: 0.7513 - val_mae: 1.4995\n",
      "Epoch 492/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7513 - mae: 1.4995 - val_loss: 0.7513 - val_mae: 1.4995\n",
      "Epoch 493/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7513 - mae: 1.4995 - val_loss: 0.7513 - val_mae: 1.4995\n",
      "Epoch 494/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7513 - mae: 1.4995 - val_loss: 0.7513 - val_mae: 1.4995\n",
      "Epoch 495/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7513 - mae: 1.4995 - val_loss: 0.7513 - val_mae: 1.4995\n",
      "Epoch 496/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7513 - mae: 1.4995 - val_loss: 0.7513 - val_mae: 1.4995\n",
      "Epoch 497/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7513 - mae: 1.4995 - val_loss: 0.7513 - val_mae: 1.4995\n",
      "Epoch 498/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7513 - mae: 1.4995 - val_loss: 0.7513 - val_mae: 1.4995\n",
      "Epoch 499/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7513 - mae: 1.4995 - val_loss: 0.7513 - val_mae: 1.4994\n",
      "Epoch 500/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7513 - mae: 1.4994 - val_loss: 0.7512 - val_mae: 1.4994\n",
      "Epoch 501/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7512 - mae: 1.4994 - val_loss: 0.7512 - val_mae: 1.4994\n",
      "Epoch 502/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7512 - mae: 1.4994 - val_loss: 0.7512 - val_mae: 1.4994\n",
      "Epoch 503/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7512 - mae: 1.4994 - val_loss: 0.7512 - val_mae: 1.4994\n",
      "Epoch 504/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7512 - mae: 1.4994 - val_loss: 0.7512 - val_mae: 1.4994\n",
      "Epoch 505/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7512 - mae: 1.4994 - val_loss: 0.7512 - val_mae: 1.4994\n",
      "Epoch 506/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7512 - mae: 1.4994 - val_loss: 0.7512 - val_mae: 1.4994\n",
      "Epoch 507/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7512 - mae: 1.4994 - val_loss: 0.7512 - val_mae: 1.4994\n",
      "Epoch 508/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7512 - mae: 1.4994 - val_loss: 0.7512 - val_mae: 1.4994\n",
      "Epoch 509/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7512 - mae: 1.4994 - val_loss: 0.7512 - val_mae: 1.4994\n",
      "Epoch 510/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7512 - mae: 1.4994 - val_loss: 0.7512 - val_mae: 1.4994\n",
      "Epoch 511/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7512 - mae: 1.4994 - val_loss: 0.7511 - val_mae: 1.4994\n",
      "Epoch 512/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7511 - mae: 1.4994 - val_loss: 0.7511 - val_mae: 1.4994\n",
      "Epoch 513/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7511 - mae: 1.4994 - val_loss: 0.7511 - val_mae: 1.4994\n",
      "Epoch 514/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7511 - mae: 1.4994 - val_loss: 0.7511 - val_mae: 1.4994\n",
      "Epoch 515/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7511 - mae: 1.4994 - val_loss: 0.7511 - val_mae: 1.4994\n",
      "Epoch 516/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7511 - mae: 1.4994 - val_loss: 0.7511 - val_mae: 1.4994\n",
      "Epoch 517/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7511 - mae: 1.4994 - val_loss: 0.7511 - val_mae: 1.4994\n",
      "Epoch 518/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7511 - mae: 1.4994 - val_loss: 0.7511 - val_mae: 1.4994\n",
      "Epoch 519/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7511 - mae: 1.4994 - val_loss: 0.7511 - val_mae: 1.4994\n",
      "Epoch 520/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7511 - mae: 1.4994 - val_loss: 0.7511 - val_mae: 1.4994\n",
      "Epoch 521/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7511 - mae: 1.4994 - val_loss: 0.7511 - val_mae: 1.4994\n",
      "Epoch 522/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7511 - mae: 1.4994 - val_loss: 0.7510 - val_mae: 1.4994\n",
      "Epoch 523/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7510 - mae: 1.4994 - val_loss: 0.7510 - val_mae: 1.4994\n",
      "Epoch 524/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7510 - mae: 1.4994 - val_loss: 0.7510 - val_mae: 1.4994\n",
      "Epoch 525/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7510 - mae: 1.4994 - val_loss: 0.7510 - val_mae: 1.4994\n",
      "Epoch 526/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7510 - mae: 1.4994 - val_loss: 0.7510 - val_mae: 1.4994\n",
      "Epoch 527/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7510 - mae: 1.4994 - val_loss: 0.7510 - val_mae: 1.4994\n",
      "Epoch 528/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7510 - mae: 1.4994 - val_loss: 0.7510 - val_mae: 1.4994\n",
      "Epoch 529/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7510 - mae: 1.4994 - val_loss: 0.7510 - val_mae: 1.4994\n",
      "Epoch 530/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7510 - mae: 1.4994 - val_loss: 0.7510 - val_mae: 1.4994\n",
      "Epoch 531/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7510 - mae: 1.4994 - val_loss: 0.7510 - val_mae: 1.4994\n",
      "Epoch 532/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7510 - mae: 1.4994 - val_loss: 0.7509 - val_mae: 1.4994\n",
      "Epoch 533/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7509 - mae: 1.4994 - val_loss: 0.7509 - val_mae: 1.4994\n",
      "Epoch 534/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7509 - mae: 1.4994 - val_loss: 0.7509 - val_mae: 1.4994\n",
      "Epoch 535/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7509 - mae: 1.4994 - val_loss: 0.7509 - val_mae: 1.4994\n",
      "Epoch 536/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7509 - mae: 1.4994 - val_loss: 0.7509 - val_mae: 1.4994\n",
      "Epoch 537/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7509 - mae: 1.4994 - val_loss: 0.7509 - val_mae: 1.4994\n",
      "Epoch 538/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7509 - mae: 1.4994 - val_loss: 0.7509 - val_mae: 1.4994\n",
      "Epoch 539/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7509 - mae: 1.4994 - val_loss: 0.7509 - val_mae: 1.4994\n",
      "Epoch 540/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7509 - mae: 1.4994 - val_loss: 0.7509 - val_mae: 1.4994\n",
      "Epoch 541/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7509 - mae: 1.4994 - val_loss: 0.7509 - val_mae: 1.4994\n",
      "Epoch 542/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7509 - mae: 1.4994 - val_loss: 0.7509 - val_mae: 1.4994\n",
      "Epoch 543/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7509 - mae: 1.4994 - val_loss: 0.7508 - val_mae: 1.4994\n",
      "Epoch 544/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7508 - mae: 1.4994 - val_loss: 0.7508 - val_mae: 1.4994\n",
      "Epoch 545/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7508 - mae: 1.4994 - val_loss: 0.7508 - val_mae: 1.4994\n",
      "Epoch 546/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7508 - mae: 1.4994 - val_loss: 0.7508 - val_mae: 1.4994\n",
      "Epoch 547/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7508 - mae: 1.4994 - val_loss: 0.7508 - val_mae: 1.4994\n",
      "Epoch 548/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7508 - mae: 1.4994 - val_loss: 0.7508 - val_mae: 1.4994\n",
      "Epoch 549/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7508 - mae: 1.4994 - val_loss: 0.7508 - val_mae: 1.4994\n",
      "Epoch 550/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7508 - mae: 1.4994 - val_loss: 0.7508 - val_mae: 1.4994\n",
      "Epoch 551/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7508 - mae: 1.4994 - val_loss: 0.7508 - val_mae: 1.4994\n",
      "Epoch 552/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7508 - mae: 1.4994 - val_loss: 0.7508 - val_mae: 1.4994\n",
      "Epoch 553/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7508 - mae: 1.4994 - val_loss: 0.7507 - val_mae: 1.4994\n",
      "Epoch 554/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7507 - mae: 1.4994 - val_loss: 0.7507 - val_mae: 1.4994\n",
      "Epoch 555/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7507 - mae: 1.4994 - val_loss: 0.7507 - val_mae: 1.4994\n",
      "Epoch 556/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7507 - mae: 1.4994 - val_loss: 0.7507 - val_mae: 1.4994\n",
      "Epoch 557/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7507 - mae: 1.4994 - val_loss: 0.7507 - val_mae: 1.4994\n",
      "Epoch 558/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7507 - mae: 1.4994 - val_loss: 0.7507 - val_mae: 1.4994\n",
      "Epoch 559/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7507 - mae: 1.4994 - val_loss: 0.7507 - val_mae: 1.4994\n",
      "Epoch 560/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7507 - mae: 1.4994 - val_loss: 0.7507 - val_mae: 1.4994\n",
      "Epoch 561/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7507 - mae: 1.4994 - val_loss: 0.7507 - val_mae: 1.4994\n",
      "Epoch 562/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7507 - mae: 1.4994 - val_loss: 0.7507 - val_mae: 1.4994\n",
      "Epoch 563/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7507 - mae: 1.4994 - val_loss: 0.7507 - val_mae: 1.4994\n",
      "Epoch 564/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7507 - mae: 1.4994 - val_loss: 0.7506 - val_mae: 1.4994\n",
      "Epoch 565/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7506 - mae: 1.4994 - val_loss: 0.7506 - val_mae: 1.4994\n",
      "Epoch 566/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7506 - mae: 1.4994 - val_loss: 0.7506 - val_mae: 1.4994\n",
      "Epoch 567/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7506 - mae: 1.4994 - val_loss: 0.7506 - val_mae: 1.4994\n",
      "Epoch 568/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7506 - mae: 1.4994 - val_loss: 0.7506 - val_mae: 1.4994\n",
      "Epoch 569/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7506 - mae: 1.4994 - val_loss: 0.7506 - val_mae: 1.4994\n",
      "Epoch 570/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7506 - mae: 1.4994 - val_loss: 0.7506 - val_mae: 1.4994\n",
      "Epoch 571/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7506 - mae: 1.4994 - val_loss: 0.7506 - val_mae: 1.4994\n",
      "Epoch 572/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7506 - mae: 1.4994 - val_loss: 0.7506 - val_mae: 1.4994\n",
      "Epoch 573/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7506 - mae: 1.4994 - val_loss: 0.7506 - val_mae: 1.4994\n",
      "Epoch 574/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7506 - mae: 1.4994 - val_loss: 0.7505 - val_mae: 1.4994\n",
      "Epoch 575/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7505 - mae: 1.4994 - val_loss: 0.7505 - val_mae: 1.4993\n",
      "Epoch 576/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7505 - mae: 1.4993 - val_loss: 0.7505 - val_mae: 1.4993\n",
      "Epoch 577/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7505 - mae: 1.4993 - val_loss: 0.7505 - val_mae: 1.4993\n",
      "Epoch 578/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7505 - mae: 1.4993 - val_loss: 0.7505 - val_mae: 1.4993\n",
      "Epoch 579/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7505 - mae: 1.4993 - val_loss: 0.7505 - val_mae: 1.4993\n",
      "Epoch 580/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7505 - mae: 1.4993 - val_loss: 0.7505 - val_mae: 1.4993\n",
      "Epoch 581/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7505 - mae: 1.4993 - val_loss: 0.7505 - val_mae: 1.4993\n",
      "Epoch 582/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7505 - mae: 1.4993 - val_loss: 0.7505 - val_mae: 1.4993\n",
      "Epoch 583/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7505 - mae: 1.4993 - val_loss: 0.7505 - val_mae: 1.4993\n",
      "Epoch 584/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7505 - mae: 1.4993 - val_loss: 0.7504 - val_mae: 1.4993\n",
      "Epoch 585/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7504 - mae: 1.4993 - val_loss: 0.7504 - val_mae: 1.4993\n",
      "Epoch 586/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7504 - mae: 1.4993 - val_loss: 0.7504 - val_mae: 1.4993\n",
      "Epoch 587/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7504 - mae: 1.4993 - val_loss: 0.7504 - val_mae: 1.4993\n",
      "Epoch 588/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7504 - mae: 1.4993 - val_loss: 0.7504 - val_mae: 1.4993\n",
      "Epoch 589/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7504 - mae: 1.4993 - val_loss: 0.7504 - val_mae: 1.4993\n",
      "Epoch 590/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7504 - mae: 1.4993 - val_loss: 0.7504 - val_mae: 1.4993\n",
      "Epoch 591/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7504 - mae: 1.4993 - val_loss: 0.7504 - val_mae: 1.4993\n",
      "Epoch 592/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7504 - mae: 1.4993 - val_loss: 0.7504 - val_mae: 1.4993\n",
      "Epoch 593/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7504 - mae: 1.4993 - val_loss: 0.7504 - val_mae: 1.4993\n",
      "Epoch 594/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7504 - mae: 1.4993 - val_loss: 0.7503 - val_mae: 1.4993\n",
      "Epoch 595/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7503 - mae: 1.4993 - val_loss: 0.7503 - val_mae: 1.4993\n",
      "Epoch 596/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7503 - mae: 1.4993 - val_loss: 0.7503 - val_mae: 1.4993\n",
      "Epoch 597/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7503 - mae: 1.4993 - val_loss: 0.7503 - val_mae: 1.4993\n",
      "Epoch 598/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7503 - mae: 1.4993 - val_loss: 0.7503 - val_mae: 1.4993\n",
      "Epoch 599/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7503 - mae: 1.4993 - val_loss: 0.7503 - val_mae: 1.4993\n",
      "Epoch 600/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7503 - mae: 1.4993 - val_loss: 0.7503 - val_mae: 1.4993\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=600,\n",
    "                    validation_split=val_train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEDCAYAAADeP8iwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVRV19n48e9mkkFABgcEFXACQQRFQEXBeYoajXFOom1ik7dtmnY1NUnTJunvzZu0TVObZk5qhsZojIlR4xgVxFlAEVFwBBVxABVFQYZ79++PeyWogETQy4XnsxaLe/bZ+9xno/Dcc/Y++yitNUIIIURVNpYOQAghROMjyUEIIcRtJDkIIYS4jSQHIYQQt5HkIIQQ4jaSHIQQQtymWSQHpdTDSqkDSimjUiryDnVtlVJ7lVLfVynrpZTaoZTar5RaqZRyM5c7KKU+MZfvU0rF3+OuCCHEfdHkkoNSKl4p9ektxRnAJCCpDof4DZB5S9nHwHNa657AMuBZc/kTAOby4cA/lFJN7mcqhGh+msUfMq11ptb60J3qKaX8gLGYkkFV3fkxsfwAPGR+3QPYaH6P80AhUOuZiRBCWINmkRx+gvnAHwDjLeUZwHjz64eBDubX+4AJSik7pVQA0KfKPiGEsFpNJjkopXYppdIwfeofr5RKM3+NrGP7B4DzWuvUanb/DPilUioVcAXKzOULgFwgBVNi2Q5U1LMrQghhcXaWDqChaK2jwTTmAMzWWs/+iYcYgCmpjAEcATel1Bda61la6yxghPn43TBdekJrXQH89sYBlFLbgSP17IoQQlhckzlzqC+t9fNaaz+ttT8wDdiktZ4FoJRqY/5uA7wIvG/edlZKuZhfDwcqtNYHLRG/EEI0pGaRHJRSE5VSuUA/YJVSap25vL1SanUdDjFdKXUYyALygE/M5W2APUqpTGAe8EjDRy+EEPefkiW7hRBC3KpZnDkIIYT4aZrEgLS3t7f29/e3dBhCCGFVUlNTC7TWravb1ySSg7+/PykpKZYOQwghrIpS6kRN++p0WUkpNUopdUgpdVQp9Vw1+5VS6i3z/nSlVO87ta1tvSOl1PPm+ofqep+CEEKIhnPH5KCUsgXeAUZjWi5iulKqxy3VRgNdzV9zgffq0Lba9Y7M+6cBIcAo4F3zcRqc1hoZkBdCiNvV5bJSFHBUa30cQCm1GJgAVJ3PPwH4XJv+0u5USrVSSvkA/jW11Vpnmstufb8JwGKtdSmQrZQ6ao5hx911sWYn92VxfvYjFPp3xz4snI6DounUPxJbZ+eGfishhLAqdUkOvsCpKtu5QHQd6vjWsW1177ezmmPdRCk1F9NZCh07drzDIatXUmHkaNc+eJ84RNusPZQuWcBBZUNBu04YgkPxjo6ky5D+tOzgd1fHF6IpKi8vJzc3l+vXr1s6FFFHjo6O+Pn5YW9vX+c2dUkOt320B269FlNTnbq0vZv3Q2v9IfAhQGRk5F1dGwqKDCHo6w8wGDWHj+RyNHEHRal7cT5ygE6b19Ji00pOvQaXW3pQ1CWYlpGRdB02EK+wHigbmQUsmqfc3FxcXV3x9/ev7sxfNDJaay5cuEBubi4BAQF1bleX5JDLzSuN+mG6S7gudRzq0PZu3q9B2doogrt3ILh7B2AKAOcvXSVjSyr5O5LhwH58Dh2gVdp28j9+i5MOTlwMCKJF7z4EDBmAb3RvlIPDvQxRiEbj+vXrkhisiFIKLy8v8vPzf1K7uiSHZKCreUnq05gGi2fcUmcF8CvzmEI0cFlrfUYplV+HtrdaAXyplHoTaI9pkHt3XTvUUNp4tGTI+DgYHwdASVkF6alZnEzYTnnaHlpnZ+J9aC9Fiz4m3daegg5dsA2LwDeuHwFxMdi1bHm/QxbivpHEYF3u5t/rjslBa12hlPoVsA6wBRZorQ8opZ40738fWA2MAY4CxcCc2tqag50I/BtojWm9ozSt9UjzsZdgGvCuAH6ptTb85J41MCcHO6L7hRLdLxSACoORzMyTHN20jeKUFFodPUinlYupWPElh5Qiv60/htBetB0YQ9ehsbTw9rJwD4QQ4ie4MZ3Tmr/69OmjLc1oNOojOWf1yv98q7+Y+4JeFjdO7w0O1Qe7B+mD3YN0Uv8h+ocnfqvTPl2si8+ctXS4Qty1gwcPWjqEn8zFxUVrrfXp06f1Qw89VG2duLg4nZycXOtx/vnPf+pr165Vbo8ePVpfunSp3vG99NJLGtBHjhypLHvzzTc1cFNMe/bs0YBeu3btTe1tbGx0r169Kr9ee+21296jun83IEXX8He1Sdwh3RgopejSqS1dfjYRfjYRgLyCK+zfuJML23fhcHAfAds34ZC0hpzX4IKnD9dDetE6th/dRsbh1K6thXsgRNPXvn17li5detft58+fz6xZs3A2T3dfvbouizrXTc+ePVm8eDEvvvgiAEuXLqVHj5tvKVu0aBGxsbEsWrSIkSN/vD/YycmJtLS0BosFZOG9e6q9txsjp45gxr/+xOQfltJx23ZOv/4+e8c+ypmW3rTakYjDay+REx/P1v5D2PDEb9n32RJKzp6zdOhCNFrz5s3j3Xffrdx++eWX+cc//sHVq1cZOnQovXv3pmfPnixfvvy2tjk5OYSGmi4Nl5SUMG3aNMLCwpg6dSolJSWV9Z566ikiIyMJCQnhpZdeAuCtt94iLy+PwYMHM3jwYMC0dE9BQQEAb775JqGhoYSGhjJ//vzK9wsODuaJJ54gJCSEESNG3PQ+VT344IOVMR8/fhx3d3dat/5x2SOtNUuXLuXTTz9l/fr193wqsZw53Eet3Z0Z9mAcPGga5M4vvMa+xGTOJ23HISMN/x2JOGxZW3lmURrSC285sxCN2CsrD3Aw70qDHrNHezdeGhdS4/5p06bxzDPP8D//8z8ALFmyhLVr1+Lo6MiyZctwc3OjoKCAmJgYxo8fX+Ng7HvvvYezszPp6emkp6fTu3flqj+8+uqreHp6YjAYGDp0KOnp6Tz99NO8+eabJCQk4O3tfdOxUlNT+eSTT9i1axdaa6Kjo4mLi8PDw4MjR46waNEiPvroI6ZMmcI333zDrFmzbovHzc2NDh06kJGRwfLly5k6dSqffPJJ5f5t27YREBBA586diY+PZ/Xq1UyaNAkwJbrw8PDKus8//zxTp06tw0+7ZpIcLKh1KxeGPRgPD8YDtyeLgB0JkiyEuEVERATnz58nLy+P/Px8PDw86NixI+Xl5bzwwgskJSVhY2PD6dOnOXfuHO3atav2OElJSTz99NMAhIWFERYWVrlvyZIlfPjhh1RUVHDmzBkOHjx40/5bbd26lYkTJ+Li4gLApEmT2LJlC+PHjycgIKDyD3efPn3Iycmp8TjTpk1j8eLFrFu3jo0bN96UHBYtWsS0adMq6/33v/+tTA734rKSJIdGpLpkkZaQzPktpmQRKMlCNDK1fcK/lyZPnszSpUs5e/Zs5R/MhQsXkp+fT2pqKvb29vj7+9/x0kt1ZxXZ2dm88cYbJCcn4+HhwezZs+94HF3LGm0tWrSofG1ra1vjZSWAcePG8eyzzxIZGYmbm1tlucFg4JtvvmHFihW8+uqrlTe2FRUV4erqWmtsd0uSQyPWupULwyfGw8R4oPZkUeDpQ2loOK1j+9F9xCAcJVmIJmzatGk88cQTFBQUsHnzZgAuX75MmzZtsLe3JyEhgRMnalyNGoBBgwaxcOFCBg8eTEZGBunp6QBcuXIFFxcX3N3dOXfuHGvWrCE+Ph4AV1dXioqKbrusNGjQIGbPns1zzz2H1pply5bx3//+9yf3y8nJib/+9a9069btpvINGzbQq1cv1q1bV1n22GOP8d133/HII/fm6cSSHKzIrcni/CXzZagbycI8Gyr7/35MFm0G9qfbyDgc21T7PA8hrFJISAhFRUX4+vri4+MDwMyZMxk3bhyRkZGEh4cTFBRU6zGeeuop5syZQ1hYGOHh4URFRQHQq1cvIiIiCAkJITAwkAEDBlS2mTt3LqNHj8bHx4eEhITK8t69ezN79uzKYzz++ONERETUegmpJjfOhKpatGgREydOvKnsoYce4r333uORRx65bcxh1KhRvP766z/5vatqEs+QjoyM1PKwH1OySE/YXZksAs4cwbmiFID81n5U9OpD+8ED6TIsFjt3dwtHK6xVZmYmwcHBlg5D/ETV/bsppVK11pHV1ZczhyakjYcLwyYNhkmmaXbnL10jbdMu8pO24rh/L4EJq9EblnPoRUW+TyD0jqTTsDg6xffDxtHRwtELIRoTSQ5NWBsPF0Y8NAQeGgLAqXOFpK/fxqUt23DLTCNg1ddc//4rMmzsKOjUDfu+UQSOjKd9dB+UnfzXEKI5k78AzUiHtq3o8MhYeGQsWmuOnjjHgbVJXN2xE89D6fgs+ZQrSz7lvL0jF7qE4NKvH0Fjh9KqR3dZaE2IZkaSQzOllKKrfzu6PjkFnpyCwag5mHmSQ+sSKd21i3bHMmiVmcrZBW9zxNmdKyEReA0aQNCYITj5trd0+EKIe0ySgwBMz7ToGdKJniGPAY9xvdxAWkomOesT0anJ+O9LxjE5kZx/vMoFLx/KekXSfsgguowYhF2V+dhCiKZBkoOolqO9LTH9QokxL1FeeLWU1MQUzm5KokV6Cp03r0VvWknWn2wo8A1ERUYTOCoev/5R8uAjIZoAWXhP1Emrli0Y+sAAZr75PJM3fEPrhC0cf+HvpA0cz5XrFXh99yVXn3yCfb37snHCDHb+/R0uHzpc652jQtyNwsLCmxbe+ynGjBlDYWFhrXX+/Oc/s2HDhrs6/q38/f0ZOHDgTWXh4eGVi//d8Jvf/AZfX1+MRmNl2aeffkrr1q0JDw+v/Dp48GCDxFUXcuYg7opfG3f8Hn0AHn0ArTVZx86QuSaB4h07aXd4H+7/eZu8/7zNQTcvSsL70n74YLqMGozdPbrVXzQfN5LDjYX3qjIYDNja2tbYti5LbP/lL3+pV3y3Kioq4tSpU3To0IHMzMzb9huNRpYtW0aHDh1ISkqqvBsbYOrUqbz99tsNGk9dyZmDqDelFMFd2jPp1zOZ9eW/id2RwKWPl7B38i846dkB9+0J6D/NIzMqhoSRE9n68t/JT92HrvIpSYi6eu655zh27Bjh4eE8++yzJCYmMnjwYGbMmEHPnj0B0/LXffr0ISQkhA8//LCy7Y0ltmtbSnv27NmVz3zw9/fnpZdeqlwGPCsrC4D8/HyGDx9O7969+cUvfkGnTp0ql+6+1ZQpU/jqq68A053O06dPv2l/QkICoaGhPPXUUyxatKhhf1j1UKczB6XUKOBfmB71+bHW+vVb9ivz/jGYHhM6W2u9p7a2SilP4CvAH8gBpmitLyml7IGPgd7m+D7XWr9Wv26K+8nR3pb+sT3pH2v6Rc27cIU9q7dwKXELngdTCVy8gILFC8hxcuVKaB+8Bw8iaNxwWrT2vsORRWNz9v/+j9LMrAY9ZovgINq98EKN+19//XUyMjIqVyFNTExk9+7dZGRkEBAQAMCCBQvw9PSkpKSEvn378tBDD+HldfOjeuu6lLa3tzd79uzh3Xff5Y033uDjjz/mlVdeYciQITz//POsXbv2pgR0q8mTJzN79mx+//vfs3LlShYuXHjTuks3EsaECRN44YUXKC8vx97eHoCvvvqKrVu3VtbdsWMHTk5Odfgp1t8dk4NSyhZ4BxgO5ALJSqkVWuuqF79GA13NX9HAe0D0Hdo+B2zUWr+ulHrOvD0PeBhoobXuqZRyBg4qpRZprXMapsvifmvv5UZ78/0VFQYj+/Znc2T1Roy7thOwLxmH5ESO/+0vnPfxh7796DxmKL4DolDmXxAh7iQqKqoyMYDpwTzLli0D4NSpUxw5cuS25FDXpbRvLIvdp08fvv32W8C0RPeN448aNQoPD48aY/P09MTDw4PFixcTHBxc+RQ5gLKyMlavXs0///lPXF1diY6OZv369YwdOxaw7GWlupw5RAFHtdbHAZRSi4EJQNXkMAHTJ3wN7FRKtVJK+WA6K6ip7QQg3tz+MyARU3LQgItSyg5wAsqAhn2aiLAYO1sb+oR3pk94Z2AuF4uuk7JhJ+c2JuKankKXlV9RtGIRafaOXOwehnvcIILGD6dlp46WDl1Uo7ZP+PfTjecogOlMYsOGDezYsQNnZ2fi4+OrXXK7rktp36hna2tLRUUFUPsS3dWZOnUqv/zlL/n0009vKl+7di2XL1+uvBxWXFyMs7NzZXKwpLokB1/gVJXtXExnB3eq43uHtm211mcAtNZnlFJtzOVLMSWOM4Az8Fut9cVbg1JKzQXmAnTsKH84rJWnqyMjzCvNaq3JOnqGA6s2cn37NvyOpuOSsZtT77zBBU8fyntH0XHkEAKGDcTmPp1ai8bnxrLZNbl8+TIeHh44OzuTlZXFzp07GzyG2NhYlixZwrx581i/fj2XLl2qtf7EiRM5c+YMI0eOJC8vr7J80aJFfPzxx5XjENeuXSMgIIDi4uIGj/mnqktyqG7dhFvTZk116tL2VlGAAWgPeABblFIbbpx9VB5E6w+BD8G0KusdjimsgFKK4K7tCX7mEXjmEa5eLyd1y15OrU/Ace9uumxaRdmG5WTY2lEQ2AOnAbEEjR9Bq+BusrxHM+Ll5cWAAQMIDQ1l9OjRt33KHjVqFO+//z5hYWF0796dmJiYBo/hpZdeYvr06Xz11VfExcXh4+NT60N3XF1dmTdv3k1lxcXFrFu3jg8++KCyzMXFhdjYWFauXAncPubw7rvv0r9//wbuTfXuuGS3Uqof8LLWeqR5+3mAqoPESqkPgESt9SLz9iFMl4z8a2p7o475rMHH3L67UuodYKfW+r/mNguAtVrrJTXFKEt2Nw85eRfYtyqRK0lbaHsojQ5XzgFwuaUH13r1xWdYPN3GDJHlyO8xWbIbSktLsbW1xc7Ojh07dvDUU081+GM6G9q9WLI7GeiqlAoATgPTgBm31FkB/Mo8phANXDb/0c+vpe0K4DHgdfP35ebyk8AQpdQXmC4rxQDz6xCnaOL823vh/8RD8MRDlFYY2JOSRfaajdgk76LzriTUtvVk/cWGAr8u2Mb0p9sDw2gTGY6qZd67EHfj5MmTTJkyBaPRiIODAx999JGlQ2pwd0wOWusKpdSvgHWYpqMu0FofUEo9ad7/PrAa0zTWo5imss6pra350K8DS5RSP8eUEB42l78DfAJkYLos9YnWOr0hOiuajhZ2tvSLCaFfjOkZxucuXiVl7VYuJmzG48AeAr7+jItff8opx5ZcDonAK940XVYenyoaQteuXdm7d6+lw7in5ElwoskxGDX7D57g8KoNVOzcgf/x/XiUmgYw89t2REfGEDBmKB0Gxsg6UHchMzOToKAgGeexIlprsrKyftJlJUkOoskrvFpKyqbdnNmQiEt6Ml3OHcdeG7hu34KLXXviOmggweOH4xoYcOeDCbKzs3F1dcXLy0sShBXQWnPhwgWKiopuuhcEJDkIUUlrzeGccxz4fhPF27bheySNdtdMM6UvtmpLae8oOo0eSsDwOHl0ag3Ky8vJzc2t9t4B0Tg5Ojri5+dXeef1DZIchKhBcWkFKdvTObl2Ew57dtE17xCOhnLKbO250C0Mt8FxBE8cjUsHP0uHKkSDk+QgRB2dyLvEnpUbuZqUhG/WHnyuXQCgoLUfxqh+dBk3kvax0fKMbdEkSHIQ4i5cKy0nOSmNU2s24LxnJ93OHcVOGylu4UxhSG+8hw0meMIoHLw8LR2qEHdFkoMQ9XTjmRX7l/9A2bYtBB5Lx6O0CCOKfL8u2A2IJWjiKLx69ZRBWmE1JDkI0cAuFl1n9/rtnP9hEx7pyXS5eBKAKy09KO4dg9+Y4XQeGS9rQIlGTZKDEPeQwajZu+8Yh1esR+3cRrdTB3CuKK0yqB1Pj0mjcfbztXSoQtxEkoMQ99HJs4Xs+T6BKwmJ+GWlVg5q57ftCDGxdJs4mrZ9I2RZD2FxkhyEsJCr18vZvXkvp9esp+WeXXTNP46tNnLVyZWi8CjajxpOl7FDsWvZ0tKhimZIkoMQjYDRqMnIOsnB5T9g3L6FLjn7cS0vocLGlvwuobgPHUqPyWNx8m1v6VBFMyHJQYhG6MyFqySv2kzhxo20P5CC79V8AM63D8R+UBzBkx+gVUiwzH4S94wkByEaueKyCrYn7OH0yrW02ruDbhdyALjUqjXl0QPpMmkM7QfIzXeiYUlyEMKKVBiMpO49wpHv1uCwcytBeVnYGw1cc2xJUXg0vuNG0WXMUJkmK+pNkoMQVkprTVb2WfZ9sw7DlkS6ZqfjWl5imiYbHI7niGH0mDgGh9belg5VWCFJDkI0EacLrrB7+SaKNm6kU2YqbUoume7S7tQdx/h4Qh4eh2uXQEuHKayEJAchmqDC4jJ2rt/BudXraZ2+i4DC0wBc8PZF9x9I98kP0DoyAmVjY+FIRWNV7+SglBoF/AvToz4/1lq/fst+Zd4/BtNjQmdrrffU1lYp5Ql8BfgDOcAUrfUl874w4APADTACfbXWNS4eL8lBNHelFQZ27zhA9vI1uKRso/u5Y9hqI0Uu7lyL7I//hDF0GjYIG3nynaiiXslBKWULHAaGA7lAMjBda32wSp0xwK8xJYdo4F9a6+ja2iql/gZc1Fq/rpR6DvDQWs9TStkBe4BHtNb7lFJeQKHW2lBTjJIchPiR0ajZn3mSA8vWoLYl0f3kAZwMZVy3d+RSaB/ajh5B9wkjsXN3t3SowsLqmxz6AS9rrUeat58H0Fq/VqXOB0Ci1nqRefsQEI/prKDatjfqaK3PKKV8zO27mxPNDK31rLp2UJKDEDXLPn2R1GXrKUlMoPORvXiUFlGhbCjoHILr0KH0ePgBWfepmaotOdRl0rQvcKrKdi6ms4M71fG9Q9u2WuszAOYE0cZc3g3QSql1QGtgsdb6b9V0ai4wF6Bjx4516IYQzVOArycBv5oGv5pGwZUSdq5K4sL6DbTP2I3LB/M58cF88n38sR0YR9BDD+AZFiI33ok6JYfq/pfcerpRU526tK0upligL6bxi43m7LbxpoNo/SHwIZjOHO5wTCEE4O3mxAPTR8L0kZSUGdiRmMqp79fRas92uiz5nPNLPuOwuzdl0bF0mTiW9gNj5Ma7Zqou/+q5QIcq235AXh3rONTS9pxSyqfKZaXzVY61WWtdAKCUWg30Bm5KDkKI+nFysGXIiCgYEUWFwcievUc5/N0a7HdtJWjD91xZ/x1nHF240isK3wdG0WX0EGxlgcBmoy5jDnaYBpWHAqcxDSrP0FofqFJnLPArfhyQfktrHVVbW6XU34ELVQakPbXWf1BKeWBKBLFAGbAW+KfWelVNMcqYgxANR2vNoezz7Fu2loqkRLoe34dreQnltnZc6N6LVsOH0eOhsbRo09rSoYp6aoiprGOA+Zimoy7QWr+qlHoSQGv9vnkq69vAKEyXguZorVNqamsu9wKWAB2Bk8DDWuuL5n2zgOcxXYJarbX+Q23xSXIQ4t45c6GIXSsSuLxhA50yU2hbbLrxrqBDFxzihxDy8AO4deti6TDFXZCb4IQQDeJySRk71u/i3Op1eO/bRWBhLgAXvNpj7DeQbg+NpW10H7nxzkpIchBCNLiyCiO7dx4ge/lanJK3EXTuiOnGO2d3ivv2J2DSODoOiUXZ21s6VFEDSQ5CiHtKa83+rFNkfLsWtTWRoJMZOBrKKWnhzOWIGDpMGEPg6KHYODpaOlRRhSQHIcR9deRUAXu+WUt5wia6HU/DtbyEUrsWXAztg8+40XSdMEoejdoISHIQQlhMbsEVdn7zA8UbNtD5cCqepUXmmU/heI0ZRY+HxmDn4WHpMJslSQ5CiEbhfGExO1YmUrh2Hf4Hk2lTcgmDsiG/SyitRo6gx5TxMkX2PpLkIIRodAqvlbFt9Rby16zDL30nvlfzTc+mCAjGdcRwQqZOwLG9j6XDbNIkOQghGrWi6+Vs/2E3Z1eupl3adjpeOQvA+Y7dcBo2jJBpE3Hp6GfhKJseSQ5CCKtRUmZgW0IKp5evpvWebZUPMcpvH4jDkGGETH8Q184BFo6yaZDkIISwStfLDezYso+Ty1bhkbqVrhdPAlDQrhO2g4cROm0Cbt27WjhK6yXJQQhh9coqjOzckUHOslW47d5C94JsAC609sMmfgghMx7CPbibZYO0MpIchBBNSoXByO7kQxz55nvcdm2m2/nj2KC50NoXm8HDCJk+SRJFHUhyEEI0WQajZnfqIY4sXUnLHUl0P3/MnCj8sBk8lJAZk3APkkRRHUkOQohm4UaiOPz1Stx2Vj2j8DOdUcyYKImiCkkOQohmp8JgJDn1MIe/Xonrrs10v5Eo2vhhEy+JAiQ5CCGauQqDkeSUwxxeaj6jyP8xUdgOHkbIjEnNctaTJAchhDCrMBjZnXKYI0tX4LYzqUqi6GBOFBObTaKQ5CCEENW4OVFsplt+9s2JYuakJv2Uu4Z4TOgo4F+YHvX5sdb69Vv2K/P+MZgeEzpba72ntrZKKU/gK8AfyAGmaK0vVTlmR+Ag8LLW+o3a4pPkIISor8rpsUtX4LYrqTJRFLTtiN2Q4YTOmIhr186WDrNB1Ss5KKVsgcPAcCAXSAama60PVqkzBvg1puQQDfxLax1dW1ul1N+Ai1rr15VSzwEeWut5VY75DWAEdklyEELcT5WJ4usVuO/eTPd80w13BW074TB8BKGzJuPi39HCUdZfbcnBrg7to4CjWuvj5oMtBiZg+lR/wwTgc23KNDuVUq2UUj6YzgpqajsBiDe3/wxIBOaZ6z0IHAeu1bmXQgjRQOxsbegfE0z/mGDKDc+ye3cmR5eupNWuzXT74iNOfvER+X5dcB45itCZk5rk6rF1SQ6+wKkq27mYzg7uVMf3Dm3baq3PAGitzyil2gAopVwwJYnhwO/r1g0hhLg37G1tGNAvhAH9Qiir+AM7tmeQ/fVyWqck0fo/b3PsP++QHxCE+5gxhEx7EIfW3pYOuUHUJTmoaspuvRZVU526tL3VK8A/tdZXTUMZNQSl1FxgLkDHjtZ/eieEaPwc7GyIGxRG3KAwrpcb2Jq4l8jtUSkAACAASURBVFPfLKf9ni04vvMPjrz7Jvldw/AcN5YeD4/DrlUrS4d81+qSHHKBDlW2/YC8OtZxqKXtOaWUj/mswQc4by6PBiabxyRaAUal1HWt9dtV31Br/SHwIZjGHOrQDyGEaDCO9rYMGx4JwyO5VlrBlvW7OLNsBZ32bcP+H/9H5j//SkFwBG0njKPbpDFW98zsugxI22EaVB4KnMY0qDxDa32gSp2xwK/4cUD6La11VG1tlVJ/By5UGZD21Fr/4Zb3fhm4KgPSQghrUVhcxpZVWyhYsYrAjB20KSmkzNaeiz0j8Z00gS7jR2Lj6GjpMIGGmco6BpiPaTrqAq31q0qpJwG01u+bp7K+DYzCNJV1jtY6paa25nIvYAnQETgJPKy1vnjL+76MJAchhJUquFLC1uUJFK5aTdfM3XiWFnHdvgWFEf3wnzyBTqOGYOPgYLH45CY4IYSwsLOXrrF16XqK166l++EU3MqLKWnhzJW+sXSeMhG/IbEou7pc6W84khyEEKIROXn+Mju/Xkvp+nX0OLYH54pSrjq5Utwvjq7TJuITG4OysbnncUhyEEKIRupY7gV2f7UKw8YfCDmxD0dDOVdaelAWO5jgRx7Gq3cvapu5WR+SHIQQopHTWpOVfY49X63EJmEDIbkHsDcaKPRoix46ktBHJjf4goCSHIQQwoporUk7eJL0Rctx2bqR4LNHTOs8+fjTYsQoej4yGSc/33q/jyQHIYSwUhUGI7uSD3P4q2V470qky8WTAJz3D8btgbGETJ+Ig5fnXR1bkoMQQjQB18sNbNucxsmvv8N3TxIdis6T3bkXY1Ytvqvj1XfhPSGEEI2Ao70tQ4f1gWF9KLpezpY122hpf29mNUlyEEIIK+TqaM+YifH37Pj3fiKtEEIIqyPJQQghxG2axIC0UiofOHGXzb2BggYMx5KkL41PU+kHSF8aq/r0pZPWunV1O5pEcqgPpVRKTaP11kb60vg0lX6A9KWxuld9kctKQgghbiPJQQghxG0kOZifJtdESF8an6bSD5C+NFb3pC/NfsxBCCHE7eTMQQghxG0kOQghhLhNs00OSqlRSqlDSqmjSqnnLB3PnSilFiilziulMqqUeSqlflBKHTF/96iy73lz3w4ppUZaJurqKaU6KKUSlFKZSqkDSqnfmMutrj9KKUel1G6l1D5zX14xl1tdXwCUUrZKqb1Kqe/N29bajxyl1H6lVJpS6sbz7K21L62UUkuVUlnm35l+96UvWutm9wXYAseAQMAB2Af0sHRcd4h5ENAbyKhS9jfgOfPr54C/ml/3MPepBRBg7qutpftQJW4foLf5tStw2Byz1fUHUEBL82t7YBcQY419Mcf3O+BL4Hsr/z+WA3jfUmatffkMeNz82gFodT/60lzPHKKAo1rr41rrMmAxMMHCMdVKa50EXLyleAKm/ziYvz9YpXyx1rpUa50NHMXU50ZBa31Ga73H/LoIyAR8scL+aJOr5k1785fGCvuilPIDxgIfVym2un7Uwur6opRyw/TB8D8AWusyrXUh96EvzTU5+AKnqmznmsusTVut9Rkw/cEF2pjLraZ/Sil/IALTJ26r7I/5UkwacB74QWttrX2ZD/wBMFYps8Z+gClBr1dKpSql5prLrLEvgUA+8In5ct/HSikX7kNfmmtyqO5p3U1pTq9V9E8p1RL4BnhGa32ltqrVlDWa/mitDVrrcMAPiFJKhdZSvVH2RSn1AHBea51a1ybVlFm8H1UM0Fr3BkYDv1RKDaqlbmPuix2my8nvaa0jgGuYLiPVpMH60lyTQy7Qocq2H5BnoVjq45xSygfA/P28ubzR908pZY8pMSzUWn9rLrba/gCYT/cTgVFYX18GAOOVUjmYLrMOUUp9gfX1AwCtdZ75+3lgGaZLK9bYl1wg13w2CrAUU7K4531prskhGeiqlApQSjkA04AVFo7pbqwAHjO/fgxYXqV8mlKqhVIqAOgK7LZAfNVSSilM11AztdZvVtlldf1RSrVWSrUyv3YChgFZWFlftNbPa639tNb+mH4fNmmtZ2Fl/QBQSrkopVxvvAZGABlYYV+01meBU0qp7uaiocBB7kdfLD0Sb6kvYAymWTLHgD9aOp46xLsIOAOUY/p08HPAC9gIHDF/96xS/4/mvh0CRls6/lv6EovpVDcdSDN/jbHG/gBhwF5zXzKAP5vLra4vVeKL58fZSlbXD0zX6feZvw7c+P22xr6YYwsHUsz/x74DPO5HX2T5DCGEELdprpeVhBBC1EKSgxBCiNtIchBCCHEbO0sH0BC8vb21v7+/pcMQQgirkpqaWqBreIZ0k0gO/v7+pKSkWDoMIYSwKkqpEzXtk8tKQgghbtOsk0N56VXSd79N+eVcS4cihBCNSpO4rHS3Mg8vZ2bmBzgeeI+eBhsiXHyJaNeXXl3H49q+D9g069wphGjGmnVy8O88in+UXWFvbhJ7Lx/jP6W5GE6eRp1YRrcKIxEOnkR4hdE7cCTtOg8DBxdLhyxEo1FeXk5ubi7Xr1+3dCjiDhwdHfHz88Pe3r7ObZrEHdKRkZG6IQaki8uukZ69nr3ZP7D3Qgb7yi9RbF7j0KeiggjlQoRHNyI6DaVL9/HYulQ7yC9Es5CdnY2rqyteXl6YlssSjZHWmgsXLlBUVERAQMBN+5RSqVrryOraSXKoRYWxgsNnU9h7ZBV7z6WwtziP88q01L2rwUgvbU9vt0D6dBhIaNBDOLTq2OAxCNFYZWZmEhQUJInBCmitycrKIjg4+Kby2pJDs76sdCd2Nnb0aB9Dj/YxzMT0Az5deJy9h5ez9/Q29hbl8FbxETh0hBaZH9PLaEtky45E+sbSM2gSjl5dQX5xRBMmicE63M2/kySHn0AphZ9HZ/yif8c4fgdAYXEBqYe+JeVkAqmXj/JeSQ762Ansj35Bzwro4+xHZPsYwrtPwrldT0kWQgirIMmhnlo5ezM0Yi5DI0xPIrxyvZC9R1aQkrORlMIsFpTl8tGJb7DLWUqPciORTj5EtosiovsEWvr2BRtbC/dACOvVsmVLrl69eueK4ieT5NDA3BxbEdfzUeJ6PgrAtbKr7D22htTs9aRcPMDnFedZcPp7bHJXElxuINKxLZHt+hLRfRLuftEyfVYI0ShIcrjHXBxaEhv8MLHBDwNQUlHCvpwNpBxbQ0rBfr4sv8BneWtRp9fQrcJIpGMbIttF0af7RDx8JVkIK7HmOTi7v2GP2a4njH69TlW11vzhD39gzZo1KKV48cUXmTp1KmfOnGHq1KlcuXKFiooK3nvvPfr378/Pf/5zUlJSUErxs5/9jN/+9rcNG3sTIMnhPnOycyKmyzhiuowDoNRQSnrOJlKOfk9qQTrflF9g4ek1cHoNXSqM9G3Rhuh20UQGT8a9fR8ZsxCiGt9++y1paWns27ePgoIC+vbty6BBg/jyyy8ZOXIkf/zjHzEYDBQXF5OWlsbp06fJyMgAoLCw0MLRN06SHCyshW0L+nYeTd/OowEoN5STkbORlKMrSclP57uKfBadXoXK/Z6gCk2Ukw9R7fvRO3gKLduGSrIQjUMdP+HfK1u3bmX69OnY2trStm1b4uLiSE5Opm/fvvzsZz+jvLycBx98kPDwcAIDAzl+/Di//vWvGTt2LCNGjLBo7I2VJIdGxt7WnojOo4joPIongPKKMvZn/8CuoyvZXZDOl+Vn+ezkd9ieWEZIBUS7+NHXdwDhwQ/j1DrI0uELYRE13a81aNAgkpKSWLVqFY888gjPPvssjz76KPv27WPdunW88847LFmyhAULFtzniBs/uQnOylwvLyHt2Bp2H1vF7osHyDBcxaAU9lrTq0IR1bIjUX6DCOvxMPaegZYOVzRhmZmZt91Udb/dmK307bff8sEHH7B69WouXrxIZGQku3btorS0FF9fX+zs7Jg/fz45OTm8+OKLODg44ObmRlpaGrNnzyYtLc2i/bgfqvv3kpvgmhBHeydigiYREzQJMM2GSj28guTsdey6lMl710/w7rEvcDryOeEGG6JcA4juOJjg4Iexa+Vn4eiFuDcmTpzIjh076NWrF0op/va3v9GuXTs+++wz/v73v2Nvb0/Lli35/PPPOX36NHPmzMFoNK128Nprr1k4+sZJzhyamMsll0g5/B27c35g9+XDHNWlALQ0GuljtCPKvRtRASPp1uMhbJw8LBytsGaN4cxB1J2cOTRz7k4eDO01h6G95gBQcO08KYeXsStnA8lXjrH5WhZkZNFq35tEKxeivUKJ6TqBDl3HgJ2DhaMXQjQWkhyaOG+XNoyK+AWjIn4BwNnLJ9id+TW7Tm1m57WTrLuUArtT8N3+AjH2nsS060t08BQ8/GJkJpQQzZgkh2amnXsnxsf8nvExv0drTfb5dHZmLmHnmZ2sKz3PN2c2wJkNBJUbiXH2JcYvlt4hM3Dy6mLp0IUQ95Ekh2ZMKUVg214Etu3FDExLlB88kcjOQ8vYWZDGF2V5fJr9NfbHlxBusCHarTMx/sMI6TEVOxdvS4cvhLiHJDmISnY2doQFDCMsYBhzMT38aO/h5ew8vppdl7J4u/gobx88SsuMd+mLI/09QxnQdQIduo0FuxaWDl8I0YDqlRyUUqOAfwG2wMda69dv2f8sMLPKewUDrbXWF5VSOUARYAAqbh0xV0r9Hvi7uX5BfeIUd8fZwYUBoTMYEDoDgItXz7E7cwk7T2xk59UcEgr3QPIeOmx/kf72nvRvF0VUjym09I2SNaGEsHJ3/RuslLIF3gFGAz2A6UqpHlXraK3/rrUO11qHA88Dm7XWF6tUGWzef2ti6AAMB07ebXyi4Xm2bMuovr/m5cnfseaxvawcs4jn/ScQ6OLDCn2Z35z9gYEbH+ex/4Ty4ZcjydjyOsZLOZYOW4hKLVu2BCAvL4/JkydXWyc+Pp47TY2fP38+xcXFldtjxoxpkDWaXn75Zd544416H6ch1OfMIQo4qrU+DqCUWgxMAA7WUH86sKiOx/4n8AdgeT3iE/eQUgr/1qH4x/0vMzCtCZWWs5Fth5exvWAf/y7P49/HF9LqyOf0M9rTzzOE/l0n0rb7GHBwsXT4oplr3749S5cuvev28+fPZ9asWTg7OwOwevXqhgqt0ahPcvAFTlXZzgWiq6uolHIGRgG/qlKsgfVKKQ18oLX+0Fx3PHBaa72vtkfbKaXmAnMBOnaUZzdbmr2tPX07j6Jv51E8A1woLmDHoWXsyFnL9ivHWFO0H/bsp8vOP9HfwYsB7fvTu8d0HNtHyJTZJuCvu/9K1sWsBj1mkGcQ86Lm1bh/3rx5dOrUif/5n/8BTJ+6XV1d+cUvfsGECRO4dOkS5eXl/O///i8TJky4qW1OTg4PPPAAGRkZlJSUMGfOHA4ePEhwcDAlJSWV9Z566imSk5MpKSlh8uTJvPLKK7z11lvk5eUxePBgvL29SUhIwN/fn5SUFLy9vXnzzTcr12p6/PHHeeaZZ8jJyWH06NHExsayfft2fH19Wb58OU5OTjX2Ly0tjSeffJLi4mI6d+7MggUL8PDw4K233uL999/Hzs6OHj16sHjxYjZv3sxvfvMbwPTBLSkpCVdX17v+2UP9kkN1v9E13W49Dth2yyWlAVrrPKVUG+AHpVQWkAL8EbjjMonmZPIhmO6Q/kmRi3vOy9mbByKe4IGIJ9Baczg/g+2Zi9met51FpQV8nreWFrmr6VMB/V0D6R84mi49pqBayiwoUTfTpk3jmWeeqUwOS5YsYe3atTg6OrJs2TLc3NwoKCggJiaG8ePH1/gc5ffeew9nZ2fS09NJT0+nd+/elfteffVVPD09MRgMDB06lPT0dJ5++mnefPNNEhIS8Pa++f9ramoqn3zyCbt27UJrTXR0NHFxcXh4eHDkyBEWLVrERx99xJQpU/jmm2+YNWtWjf179NFH+fe//01cXBx//vOfeeWVV5g/fz6vv/462dnZtGjRovJS1htvvME777zDgAEDuHr1Ko6OjvX98dYrOeQCHaps+wF5NdSdxi2XlLTWeebv55VSyzBdproEBAA3zhr8gD1KqSit9dl6xCosSClF9zY96d6mJ3MwPfAo5fh6th/5ju0XMnijNAcy36PN/n/TT7kwoHU4MUEP4xE4BGztLR2+qIPaPuHfKxEREZw/f568vDzy8/Px8PCgY8eOlJeX88ILL5CUlISNjQ2nT5/m3LlztGvXrtrjJCUl8fTTTwMQFhZGWFhY5b4lS5bw4YcfUlFRwZkzZzh48OBN+2+1detWJk6ciIuL6dLppEmT2LJlC+PHjycgIIDw8HAA+vTpQ05OTo3HuXz5MoWFhcTFxQHw2GOP8fDDD1fGOHPmTB588EEefPBBAAYMGMDvfvc7Zs6cyaRJk/Dzq/86avVJDslAV6VUAHAaUwKYcWslpZQ7EAfMqlLmAthorYvMr0cAf9Fa7wfaVKmXA0TKbKWmxcnOiYHdJjCwm+lU/2zRabZnfsW2E5tIuHaS5Rd3obbtpEeigf6OPvTvEEev0BnYe3e1cOSisZk8eTJLly7l7NmzTJs2DYCFCxeSn59Pamoq9vb2+Pv7c/369VqPU91ZRXZ2Nm+88QbJycl4eHgwe/bsOx6ntrXqWrT4cbq3ra3tTZevfopVq1aRlJTEihUr+H//7/9x4MABnnvuOcaOHcvq1auJiYlhw4YNBAXVbwn/u56tpLWuwDSGsA7IBJZorQ8opZ5USj1ZpepEYL3W+lqVsrbAVqXUPmA3sEprvfZuYxHWrZ2rL5Oifsc/Hv6epEf3snDo+zzlOwwHZy8WGPKZc2IpA1c+yK8/DmPx0imc2vcFlMpD5YXp0tLixYtZunRp5eyjy5cv06ZNG+zt7UlISODEiRO1HmPQoEEsXLgQgIyMDNLT0wG4cuUKLi4uuLu7c+7cOdasWVPZxtXVlaKiomqP9d1331FcXMy1a9dYtmwZAwcO/Mn9cnd3x8PDgy1btgDw3//+l7i4OIxGI6dOnWLw4MH87W9/o7CwkKtXr3Ls2DF69uzJvHnziIyMJCur/uM/9brPQWu9Glh9S9n7t2x/Cnx6S9lxoFcdju9fn/iE9bG1sSXMbwBhfgN4CrhSepnkIyvYdnQV2y8fJvFaJqRl4pf8KgPsWpnurQiZTku/aBnYboZCQkIoKirC19cXHx8fAGbOnMm4ceOIjIwkPDz8jp+gn3rqKebMmUNYWBjh4eFERUUB0KtXLyIiIggJCSEwMJABAwZUtpk7dy6jR4/Gx8eHhISEyvLevXsze/bsymM8/vjjRERE1HoJqSafffZZ5YB0YGAgn3zyCQaDgVmzZnH58mW01vz2t7+lVatW/OlPfyIhIQFbW1t69OjB6NGjf/L73UqW7BZWQ2vNyUtH2XbwS7bnbmH39XOUKLDTmrByTaxbILGBowkKnYFyamXpcJs8WbLbusiS3aLJUkrRybMrnWJf+vHeihOb2J71DdsK0njreg5vHXwP7/S3ibV1I7ZtX/qFzsRNziqE+MkkOQirZW9rT9/AkfQNHMlvgIKrZ9l2YCFbTmxgY3Eu351PxHZjAr0qNANdOzOw8xi6hUyTswoh6kAuK4kmqcJYQfqJRLZmLWFrfhqZ2jQzpE2FgVhbNwa2iyYmdCYtffvKWcVdyszMJCgoqMb7B0TjobUmKyvrJ11WkuQgmoX8ojy2HljIlhMb2VlymiLzWEVEuSbWvQsDAx+gS8gUlJO7pUO1GtnZ2bi6uuLl5SUJohHTWnPhwgWKiooICAi4aZ8kByGqKDeWk56ziS1ZX7O1YB+HtGnuetsKAwNt3Yn1iSYmdBYu7fvIWUUtysvLyc3NvePcf2F5jo6O+Pn5YW9/802lkhyEqMW5otNsy/iCrSc3sb0kj2vms4o+5TCoVXfiuk2kU4+HwL7mdXCEsEaSHISoo3JjOWnZG9iS9TVbLqRzVJcC0Km8gkEObRjUIY4+vWZj7xlo4UiFqD9JDkLcpdOF2STt/4zNuUkkl+ZTpsDFaKS/0YFB3r2IDZmBd+BQsLG1dKhC/GSSHIRoAMVl19h1+DuSjnxH0uUjnFcGAHqWGRjYshODAkcT3HMmNs5eFo5UiLqR5CBEA9Nac+hMCpsPfEHS2d3sNxShlaJ1hYGBNq4Mat+Pfj0fw9knXAa1RaMlyUGIe+xicT5bMxayOWcd24tzuarAXmv6VigGtQpiUPdJdAiaCPb1X2dfiIYiyUGI+6jcWM7e4z+QlLWEzRf2k0MZAAHlFcS1aEtcx6GE95qDXav6r7kvRH1IchDCgk5ePELS/s9JOr2F5LILVChwNxgYhDPx7WLoH/ao3KktLEKSgxCNxLWyq2zP/JrEo8vZXHScy0pjpzVRFYp4j2Dig6bg03082DlYOlTRDEhyEKIRqjBWsO9EIokHvySxYF/l5aeg8grinDowuPMYgnvOwsZFnqst7g1JDkJYgeyCTDbv/4yEvK2klRdiVIo2FQbibN2J9x1IdK85tGgjz08QDUeSgxBW5lLxBbYcWEhi9hq2FedSrMDJaKSfwY741uEMCpmJl9x8J+pJkoMQVqzMUEby0e9JyPqaxMJMzmFAaU2vciPxbp2J7zqBwB5TUY6ulg5VWBlJDkI0EVprss6mkLj/cxLPJXPQeA2ADuUVxDu0ZnDHIUSE/xy7Vh0sHKmwBpIchGiizl7JJWn/ZySc3MSu0vOUK3AzGBiIE/FtoxjQ8zFcO8hjUkX1JDkI0QwUl11jR9ZSEo58R1LRMS6Zp8lGlkO8RzBDe0yjXbdxMk1WVJLkIEQzYzAaSD+ZRMLBhSQWpJFtXnq8R1kFQ1r6M6Trg3QJnY5ydLNwpMKSJDkI0cxlX8giYd8CNuZtJd1QBJjGKYY6tGGI/0jCIuZg6+pj4SjF/SbJQQhRKb/oDAn7P2XTiR/YVZpPhQJPg4HBypUhfoOIDv85LVoHWTpMcR9IchBCVKuo9ApbDy5i09GVbLl2gmsKnI1GYo0ODGkTycCw2bh17C8D2k2UJAchxB2VGcrYfXQlGzOXkFCYxQVlNK37VA5DPEOI7zGDtt3GgK39nQ8mrMI9Sw5KqVHAvwBb4GOt9eu37H8WmGnetAOCgdZa64tKqRygCDAAFTcCVEr9HRgHlAHHgDla68La4pDkIETDMmoj6ae2sinjczbl7+WEed2nnmUGhrgGMqTbRAJDp4GDi4UjFfVxT5KDUsoWOAwMB3KBZGC61vpgDfXHAb/VWg8xb+cAkVrrglvqjQA2aa0rlFJ/BdBaz6stFkkOQtw7WmuyCw6wMf0TNuVtJ8N4FQD/8gqGtGjHkIBR9Az/GTYtW1s4UvFT1ZYc7Opx3CjgqNb6uPlNFgMTgGqTAzAdWHSng2qt11fZ3AlMrkeMQoh6UkoR2DqUwKH/4AlMN94l7v+UTSc28HlZPguOfUHrQ58xxNad4R2H0af3XLlDuwmoz5nDZGCU1vpx8/YjQLTW+lfV1HXGdHbRRWt90VyWDVwCNPCB1vrDatqtBL7SWn9RWyxy5iCEZVy+fpmkA1+w6dhKthaf5rqCVgYD8cqF4b6DiImYi0Pr7pYOU9TgXp05VDd9oaZMMw7YdiMxmA3QWucppdoAPyilsrTWSZUHV+qPQAWwsNo3V2ouMBegY8eOdxO/EKKe3B3dGdfnl4zr80tKKkrYlrmEDYe+ZcPV43x3Zj0up9cyyNiCYe1iiI14AmefcJn5ZCXqc+bQD3hZaz3SvP08gNb6tWrqLgO+1lp/WcOxXgauaq3fMG8/BjwJDNVaF98pFjlzEKJxKTeUs/PICjZmLmbT5cNcUkZaGI0MMNgyrE0fBoX9DPdOsZIoLOxeDUjbYRqQHgqcxjQgPUNrfeCWeu5ANtBBa33NXOYC2Giti8yvfwD+orVea54B9SYQp7XOr0sskhyEaLwqjBXszdnIhgNfsOHifs5jwE5rosthqFcYQ3o+ilfn4fJsCgu4l1NZxwDzMU1lXaC1flUp9SSA1vp9c53ZmMYmplVpFwgsM2/aAV9qrV817zsKtAAumPfv1Fo/WVsckhyEsA5GbSQjdzsb9n/Khvy9nKIMG62JKNcMa9WdYT1m0C5ogtxLcZ/ITXBCiEZHa83h82ls3Pf/27vX4KjqO4zj31+yBDGA4RqFaAhEZRAhCep4aa2VXKlUXtjWzjB1qIp22pl2+qLVsdNOX7YvOn1XbcVrrVapF3QgF0QEakVRQgj3QAOCgQBKgNx2z+6/L/Zot26MFJKcPcnzmdnZs/9s2N8zs5tn9+xydgUNRzfT4noAmBv1WDhuFhWzv0PhNd+FUWMCnnT4UjmISMZrPbmbN7c9wdojGz//vxTFMY/yMQWUFy/hqnlLsTGXBDzl8KJyEJFQaTt9iHXbVtBwaB0fxj7FmXFFzKNi9KVUzFrMnJJl2MUTgh4z9FQOIhJaJzrbWd/0FA2ttWzubSduRkHMoyInn6rixcwp+aGK4jypHERkWDjV/Qnrmp6k/sBqNvcewzNjuudRMWoKlbPuYG7JvVjupKDHDA2Vg4gMOx09p1jX9BT1B17n3Z52PINpflFUzFzEvNL7VRRfQeUgIsNaR08H67c/Tf3+VbzTcwzP4FLPoyIyicqZNcwrXa4DA/ZB5SAiI8bp3g7Wb3+Ghv2v88/uNmIG+Z5HRWQilUU1zC9bTtbYqUGPmRFUDiIyIp3pPc365mepb3mNd7rbiBpM9eKUR/KoLKymdMEDZI3LD3rMwKgcRGTEO9t7hrd3PEf9vlfZ1H2EqMEUL055dh6VMyopLVtO9vhpQY85pFQOIiIpOqNn2bDzeer3vszGrsP0Gkz24izMvoSqwkrKFiwne/z0oMccdCoHEZEv0RXtTCmKj+gxmBiPU27jqSysYEHZA0TyCoIec1CoHEREzkFXrIuNO/9O/d6VbOw8RLdfFLfbOCqvWMj1ZQ8SmTB8vj9G0wrCrAAABlBJREFU5SAi8n/q9rrZtPNF6ve8xNudB+k2mBCPU27jqC6sZMF1D4Z+15PKQUTkAiS/5W4ldbtf5O3OVrr99ygqsvOoKaph/oIHQvnxWJWDiMgA6Yp1sWHnC9TteenzN7PzPY+qyGSqZy1mbtl92MUTgx7znKgcREQGQWf0LG81P0vdvlfY1N2GZzA95lGVk0/1lUuYXbIsow8zrnIQERlkHT0drNv+JHUtq3jXP3rsjJhH1UXTqL76Lorn/wBycoMe83+oHEREhtCnXSdZ27SCugOreT96goQZxTGPqouvoHr295hx7fcz4hvuVA4iIgE50XmMhsa/UNtax4feKQBmRz2qxxZRNWcpBdfcBZGcQGZTOYiIZICjp49Q3/gYdYfW0hQ/A8C1UY+q8VdRNXcpl85eAtmjhmwelYOISIY5cqqVuq2PUnt4PbsSnQCURuNU5c2m6tplTL5qEWRlD+oMKgcRkQx28OReahsfpfbIJlpcN+Yc18cSVE+cR0XJ/eQVfROysgb8dlUOIiIhsf94M7VbH6P26L9odb1EnOOmGNRMvY7by35EbsENYDYgt6VyEBEJGeccu49+wJrGx1jTvoWjeIxOJLg1HmHRtFv4+oKfMDp/zgXdhspBRCTEEi7BtkMbWN30OPUnt/OJJchNJFiYGM3i4ju58Ru/Oa9/t79yiFzQxCIiMuiyLIvSwtsoLbyNXyY83juwhtrtz7C2Yw+u7R1uHITbVDmIiIRIJCvCzcWLubl4Mb+KRznTc2pQbmfg3/4WEZEhkZOdw6TcwTkarMpBRETSqBxERCTNsPi0kpkdBw6e569PBk4M4DhBUpbMM1xygLJkqgvJUuicm9LXD4ZFOVwIM9vyZR/lChtlyTzDJQcoS6YarCzarSQiImlUDiIikkblAH8OeoABpCyZZ7jkAGXJVIOSZcS/5yAiIun0ykFERNKoHEREJM2ILQczqzazPWbWYmYPBT3PVzGzJ8ys3cyaU9YmmlmDme3zzyek/OxhP9seM6sKZuq+mdnlZvaWme0ysx1m9lN/PXR5zOwiM3vPzLb5WX7rr4cuC4CZZZvZVjN7w78c1hytZrbdzBrNbIu/FtYseWa20sx2+4+Zm4Yki3NuxJ2AbGA/MBPIAbYBc4Ke6ytmvhUoA5pT1n4PPORvPwT8zt+e42caDRT5WbODzpAy92VAmb89Dtjrzxy6PIABY/3tUcBm4MYwZvHn+znwN+CNkN/HWoHJX1gLa5angfv87RwgbyiyjNRXDjcALc65A865KPACcGfAM/XLObcB+OQLy3eSvOPgny9JWX/BOdfrnPs30EIyc0ZwzrU55z70t88Au4DphDCPSzrrXxzlnxwhzGJmBcC3gMdTlkOXox+hy2Jm40k+MVwB4JyLOudOMQRZRmo5TAc+Srl82F8Lm3znXBsk/+ACnx2eMTT5zGwGUEryGXco8/i7YhqBdqDBORfWLH8EfgEkUtbCmAOSBV1vZh+Y2XJ/LYxZZgLHgSf93X2Pm1kuQ5BlpJZDX1/AOpw+0xuKfGY2FvgH8DPn3On+rtrHWsbkcc7FnXMlQAFwg5nN7efqGZnFzO4A2p1zH5zrr/SxFniOFLc458qAGuDHZnZrP9fN5CwRkruT/+ScKwU6Se5G+jIDlmWklsNh4PKUywXAxwHNciGOmdllAP55u7+e8fnMbBTJYnjOOfeyvxzaPAD+y/31QDXhy3IL8G0zayW5m/V2M/sr4csBgHPuY/+8HXiF5K6VMGY5DBz2X40CrCRZFoOeZaSWw/vAlWZWZGY5wN3AqoBnOh+rgHv87XuA11LW7zaz0WZWBFwJvBfAfH0yMyO5D3WXc+4PKT8KXR4zm2Jmef72GKAc2E3IsjjnHnbOFTjnZpB8PKxzzi0lZDkAzCzXzMZ9tg1UAs2EMItz7ijwkZld7S8tBHYyFFmCfic+qBOwiOSnZPYDjwQ9zznM+zzQBsRIPju4F5gEvAns888nplz/ET/bHqAm6Pm/kOVrJF/qNgGN/mlRGPMA84CtfpZm4Nf+euiypMx3G//9tFLocpDcT7/NP+347PEdxiz+bCXAFv8+9iowYSiy6PAZIiKSZqTuVhIRkX6oHEREJI3KQURE0qgcREQkjcpBRETSqBxERCSNykFERNL8Bwvl5Tj/WXYnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "epochs=600\n",
    "print(\"Plotting...\")\n",
    "f, (ax1, ax2) = plt.subplots(2, 1)\n",
    "ax1.plot(range(1, epochs+1), history.history['val_mae'], 'tab:blue', label=\"validation MAE\")\n",
    "ax1.plot(range(1, epochs+1), history.history['mae'], 'tab:red', label=\"training MAE\")\n",
    "\n",
    "ax2.plot(range(1, epochs+1), history.history['loss'], 'tab:orange', label=\"loss\")\n",
    "ax2.plot(range(1, epochs+1), history.history['val_loss'], 'tab:green', label=\"validation loss\")\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "f.savefig('training-softmax.png', dpi=300)\n",
    "plt.show()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Model-Softmax-cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
